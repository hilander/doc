\documentclass[12pt]{mwart}
%\documentclass{mwart}
\usepackage{makeidx}
\usepackage{polski}
%\usepackage{antpolt}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{graphics}
\usepackage[table]{xcolor}
\usepackage[bookmarks, pdfhighlight=/P, citebordercolor={1 1 1}, linkbordercolor={1 1 1}, unicode=true]{hyperref}
\usepackage{amsfonts}
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{hhline}
\bibliographystyle{plunsrt}
\hyphenation{ wyj-ścia pier-wszego}
\newcommand{\code}{\texttt}

\makeindex

\newcommand{\remark}{{\bf \emph{Notatka:}} \\ \emph}
\newcommand{\dcolon}{::}
\newcommand{\procbr}{()}
\newcommand{\function}[1]{\code{#1\procbr}}

\newcounter{tabmain}
\setcounter{tabmain}{1}
\newcommand{\mytabcaption}[1]{ \begin{center}\parbox[t]{11.5cm}{\normalsize{Tabela \arabic{tabmain}. #1.}}\end{center} \addtocounter{tabmain}{1} }

\newcounter{figmain}
\setcounter{figmain}{1}
\newcommand{\myfigcounter}[1]{ \begin{center}\parbox[t]{11.5cm}{Rysunek \arabic{figmain}. #1.}\end{center} \addtocounter{figmain}{1} }
\newcommand{\myownfigure}[4]{ \newcounter{#1} \setcounter{#1}{\value{figmain}} \addtocounter{figmain}{1} \begin{center} \label{fig:#1} \centering \includegraphics[scale=#4, angle=0]{#2}\\ \nopagebreak[5] \parbox[t]{11.5cm}{Rysunek \arabic{#1}. #3.} \end{center}}

\usepackage{xtab}
\tabletail{\hline}

\usepackage{fancyhdr}
\setlength{\headheight}{15.2pt}
\pagestyle{fancy}
\lhead{\leftmark}
\chead{\empty}
\rhead{\rightmark}
\lfoot{\empty}
\cfoot{\thepage}
\rfoot{\empty}
%\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
%\renewcommand{\sectionmark}[1]{\markright{#1}{}}
\renewcommand{\sectionmark}[1]{\markboth{{#1}}{}}

\linespread{1.3}
%\linespread{1.3}
%\usepackage{qswiss,qcourier}
%\usepackage{sfheaders}

%\usepackage[layout]{tools}

%\setlength{\voffset}{1cm}
%\setlength{\voffset}{1cm}
\author{Mariusz Barycz}
\title{Analiza metod zarządzania wątkami mieszanymi}
\date{\today}
\begin{document} 


\maketitle
\thispagestyle{empty}

\newpage
\tableofcontents
\thispagestyle{empty}
\newpage

\section{Wstęp}
%
\subsection{Motywacja}
\indent
  W~większości współczesnych systemów operacyjnych zrealizowano paradygmat \emph{programowania współbieżnego}.\\
  W~związku z~wykorzystaniem tego paradygmatu, powstały dwa podstawowe pojęcia: \emph{proces} oraz \emph{wątek}.
  Proces jest samodzielnym bytem, któremu system operacyjny udostępnia zasoby (lub część tych zasobów, zgodnie z~polityką udzielania zasobów
  danego systemu), zaś wątek jest bytem zależnym od procesu.
\par
%
\indent
	Dostępne obecnie architektury systemów operacyjnych są z~założenia przystosowane do równoległego
	wykonywania programów. Co więcej, architektury te obejmują wiele rodzajów urządzeń, które są obsługiwane przez system operacyjny.
	Współczesne systemy operacyjne udostępniają użytkownikowi możliwość równoległego wykonania aplikacji (przy użyciu procesów),
	zaś poszczególne aplikacje mogą być wykonane w~sposób równoległy (podział na podprocesy lub wątki). Wątki zarządzane przez system operacyjny
	zwane są wątkami przestrzeni jądra.
	Drugi rodzaj wątków to wątki przestrzeni użytkownika, które są najczęściej udostępniane jako biblioteki funkcji; co więcej, system operacyjny
	nie jest świadomy ich istnienia. Z~tych powodów zarządzanie nimi jest odpowiedzialnością użytkownika lub funkcji udostępnianych przez
	bibliotekę takich wątków.
\par
%
\indent
	Obydwa rodzaje wątków posiadają zarówno swoje zalety, jak i~wady. Istnieje rozwiązanie pośrednie: wątki mieszane, zwane również
	\emph{hybrydowymi}. W~niniejszej pracy użycie słowa ,,wątek'' oznacza odwołanie do wątku przestrzeni jądra, zaś użycie słowa ,,włókno'' oznacza odwołanie
  do wątku mieszanego.
\par
%
\indent
  Implementacja włókien w~systemie operacyjnym może wymagać zmian w~jądrze systemu.
  Przykładem takiej implementacji jest \emph{scheduler activations} (SE), opisana w~\cite{anderson}.
  Mechanizm ten został zaimplementowany w~NetBSD, jednakże działanie systemu operacyjnego z~tą implementacją wpływała negatywnie na jego działanie, 
  dlatego obecne wydania NetBSD dają możliwość wyboru systemu z~jądrem zmodyfikowanym przez SE, ale jedynie na wyraźne żądanie użytkownika systemu.
  Implementacja włókien oparta na podobnym do SE pomyśle jest oferowana także w~systemie Windows 7.
\par
%
\indent
  \myownfigure{mixedintro}{mixedscheme.png}{Włókna w~implementacji nie wymagającej zmian w~systemie~operacyjnym -- cel niniejszej pracy}{.21}
\par
\indent
  Włókna mogą być zaimplementowane również bez dokonywania zmian w~jądrze systemu operacyjnego.
  Taka implementacja może być biblioteką dołączaną przez użytkownika, zaś jej użycie nie będzie mieć wpływu na działanie i~wydajność innych programów.
\par
%
\subsection{Cel pracy}
\label{sec:target}
\indent
  Celem niniejszej pracy było utworzenie biblioteki włókien w~języku C++.
	Powinna ona odpowiadać za:
	\begin{enumerate}
		\item Zarządzanie włóknem:
		\begin{itemize}
			\item tworzenie i~destrukcja;
			\item przydział kontekstu wykonania (stosu);
			\item przydział włókna do procesora;
			\item uruchomienie i~wstrzymanie(tzn. w~momencie wywołania operacji \function{yield});
			\item prawidłowa reakcja na wystąpienie wyjątku w~trakcie działania.
		\end{itemize}
		\item Komunikację: wysyłanie i~obsługa komunikatów (po stronie zarządcy i~włókna).
		\item Nieblokujący dostęp do  urządzeń wejścia\dywiz wyjścia (z~punktu widzenia zarządcy włókien).
    \item Zarządzanie kolejnością i~czasem wykonania włókien (ang. \emph{scheduling}). \label{enm:timesch}
	\end{enumerate}
\par
%
\subsection{Streszczenie pracy}
\indent
	\begin{itemize}
	\item[Rozdział \ref{sec:architecture}] opisuje architekturę współczesnego komputera klasy PC. Opis ten koncentruje się na 
		mechanizmach umożliwiających równoległe wykonanie części lub całych rozkazów procesora oraz na zwiększeniu liczby procesorów
		w~komputerze w~celu podniesienia wydajności obliczeń. Poruszone problemy związane z~pamięcią operacyjną jak również opis połączenia
		poszczególnych elementów komputera między sobą, uzasadniają potrzebę projektowania oprogramowania, które będzie wykonywane równolegle.
	\item[Rozdział \ref{sec:system}] opisuje zgrubnie współczesne systemy operacyjne, jak również zarządzanie procesami.
	\item[Rozdział \ref{sec:solution}] opisuje implementację włókien opartą na pomyśle opisanym we wstępie.
	\item[Rozdział \ref{sec:analysis}] określa wartość tej implementacji: jej użyteczność oraz wydajność.
	\item[Rozdział \ref{sec:summary}] podsumowuje wykonanie założeń opisanych we wstępie, jak również wyznacza możliwe drogi rozwoju
		powstałej implementacji.
	\end{itemize}
\par
%
\newpage
\section{Architektura systemów komputerowych}
%
\label{sec:architecture}
\indent 
	W~systemie komputerowym (lub w~skrócie: komputerze) można wyróżnić trzy podstawowe składowe:
	\begin{itemize}
		\item procesor (jednostka centralna, CPU): kontroluje działanie komputera, wykonuje operacje na danych;
		\item pamięć główna: przechowuje dane oraz programy. Pamięć w~tym kontekście jest z~natury ulotna (po wyłączeniu komputera,
			jej zawartości nie można odzyskać); jeśli w~treści dokumentu pojawi się słowo \emph{pamięć}, odwoływać się będzie ono do
			pamięci głównej;
		\item urządzenia zewnętrzne (peryferia, I/O): służą do wymiany danych pomiędzy komputerem i~światem zewnętrznym.
	\end{itemize}
	Komunikacja pomiędzy nimi odbywa się za pośrednictwem szyny systemowej (ang. \emph{system bus}).
	Poniższe podrozdziały informują o~podstawowych składnikach systemu komputerowego. Dokładny opis architektury współczesnych
	systemów komputerowych można znaleźć w~\cite{hennessy}.
\par
%
\subsection{Procesor}
%
\indent
	Procesor jest urządzeniem, które posiada:
	\begin{itemize}
		\item własny zestaw instrukcji (zwanych również rozkazami): ich liczba może wynosić od kilkunastu (architektura RISC, 
			ang. \emph{Reduced Set Instruction Computers}) do kilkuset (architektura CISC, ang.
			\emph{Complex Instruction Set Computers}). Często pojedynczy rozkaz posiada wiele trybów adresowania: jako argument
			może użyć własnego rejestru (tryb implikowany), komórki pamięci (tryb bezpośredni), komórki pamięci, której adres został wyliczony
			(tryby: pośredni, pośredni pre-indeksowany, pośredni post-indeksowany). Połączenie instrukcji wraz z~ich trybami adresowania daje 
			stosunkową liczbę rozkazów.
		\item wewnętrzne komórki pamięci, zwane \emph{rejestrami}.
		\item Licznik rozkazów (ang. \emph{program counter}): wyróżniony rejestr, który wskazuje adres następnej instrukcji. 
			Jeśli w~wyniku ostatniej instrukcji następuje skok (warunkowy lub bezwarunkowy), zmieniana jest wartość tego rejestru.
		\item mechanizm \emph{przerwań}: szyna systemowa może w~pewnych sytuacjach poinformować o~wystąpieniu określonego zdarzenia.
			Przerwania można podzielić na maskowalne (procesor zignoruje informację o~wystąpieniu danego zdarzenia) oraz niemaskowalne.
			Przerwania mogą posiadać priorytety (przerwanie o~niższym priorytecie zostanie zignorowane podczas obsługiwania przerwania
			o~wyższym priorytecie lub jego obsługa rozpocznie się po zakończeniu obecnie obsługiwanego przerwania).
	\end{itemize}
\par
%
\indent
	Procesor przetwarza rozkazy. Można podzielić je na pięć grup:
	\begin{itemize}
		\item odczyt / zapis: wczytanie zawartości komórki pamięci do rejestru, zapis zawartości rejestru do komórki;
		\item skoki: bezwarunkowe, warunkowe, pośrednie;
		\item operacje logiczne: NOT, AND, OR, XOR;
		\item arytmetyka: suma, różnica, iloczyn, iloraz;
		\item zmiana stanu procesora: maskowanie przerwań, ustawienie / wyczyszczenie flagi przeniesienia.
	\end{itemize}
	Każdy rozkaz jest wykonywany w~określonym czasie, w~zależności od rozkazu wykorzystywane są specyficzne dla danej instrukcji
	jednostki funkcjonale CPU (np. jednostka arytmetyczno\dywiz logiczna dla rozkazów arytmetycznych, lub licznik rozkazów
	dla skoków warunkowych). Czas wykonania jest mierzony w~\emph{cyklach maszynowych}. Należy mieć na uwadze, 
	iż na jeden cykl maszynowy może składać się więcej niż jeden cykl zegarowy, zaś
	producent, informując o~taktowaniu procesora zegarem o~częstotliwości 1 MHz, ma na myśli, że
	w~ciągu sekundy zostanie wykonanych milion cykli zegarowych.
\par
%
\indent
	Wynik wykonania konkretnego rozkazu może powodować zmiany w~rejestrze jednostki centralnej, w~pamięci lub
	też w~urządzeniu zewnętrznym. Co więcej, każdy procesor wykonuje rozkazy w~pewien określony sposób, w~specyficznej dla siebie liczbie kroków.
	Jednakże, dla wszystkich procesorów, możemy wyróżnić podstawowe kroki wykonania rozkazu:
	\begin{enumerate}
	\item Pobranie (ang. \emph{Instruction Fetch, IF}): wymaga komunikacji z~pamięcią.
		Pobrany rozkaz po pobraniu jest gotowy do dalszego przetwarzania.
	\item Dekodowanie (ang. \emph{Instruction Decode, ID}):  liczba bajtów, które należy pobrać, może być zmienna:
		nawet gdy długość rozkazu jest niezmienna (np. 2 bajty), jego argumenty (\emph{opkody}, ang. \emph{opcode}) mogą być zmiennej długości.
	\item Wykonanie (ang. \emph{Execute, EX}): poszczególne części procesora wykonują działanie w~kolejności określonej przez aktualnie
		wykonywany rozkaz.
	\item Dostęp do pamięci (ang. \emph{Memory Access, MEM}): rozkazy mogą korzystać z~danych zawartych w~komórkach pamięci. Jeśli bieżący rozkaz
		zapisuje do lub odczytuje zawartość pamięci, w~tym kroku jest dokonywana ta operacja.
	\item Zapis (ang. \emph{Write Back, WB}): stan procesora jest aktualizowany o~wynik działania rozkazu.
	\end{enumerate}
\par
%
\indent
	Klasyczne procesory wykonują rozkazy sekwencyjnie. Kolejny rozkaz zostanie wczytany do pamięci dopiero, gdy
	CPU zapisze wynik bieżącego. Do sekwencyjnego wykonywania rozkazów nie potrzeba żadnych dodatkowych mechanizmów,
	jednak w~trakcie wykonania aktywna jest dokładnie jedna składowa procesora, podczas gdy pozostałe są ,,uśpione''
	w~oczekiwaniu na uruchomienie.
	\begin{center}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|} \hline
	& \multicolumn{5}{c|}{Rozkaz 1} & \multicolumn{5}{c|}{Rozkaz 2}  \\
	\hhline{|~|*{10}-}& IF & ID & {\cellcolor{yellow}{EX}} & MEM & WB & IF & ID & EX & MEM & WB\\ \hline \hline
	Cykl zegara & 1 & 2 & {\cellcolor{yellow}{3}} & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
	\end{tabular}\par
	\mytabcaption{Sekwencyjne wykonanie dwóch rozkazów. Wyróżniona kolumna odpowiada bieżącemu krokowi wykonania
	rozkazu}
	\end{center}\par
\par
%
\indent 
	Pomysł na lepsze wykorzystanie zasobów jednostki centralnej, to użycie \emph{potokowości} (ang. \emph{pipelining}):
	Jeśli wykonanie bieżącego rozkazu zakończyło się dla komponentu, może on wykonać następny rozkaz.
	\begin{center}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|} \hline
	Numer 		 & \multicolumn{7}{c|}{\multirow{2}{*}{Stan potoku}} \\
	rozkazu & \multicolumn{7}{c|}{} \\ \hline
	1 & IF & ID & EX & \cellcolor{yellow} MEM & WB & & \\ \hline
	2 & & IF & ID & \cellcolor{yellow} EX & MEM & WB & \\ \hline
	3 & & & IF & \cellcolor{yellow} ID & EX & MEM & WB \\ \hline
	4 & & & & \cellcolor{yellow} IF & ID & EX & MEM \\ \hline
	5 & & & & \cellcolor{yellow} & IF & ID & EX \\ \hline \hline
	Cykl zegara & 1 & 2 & 3 & \cellcolor{yellow} 4 & 5 & 6 & 7 \\ \hline
	\end{tabular}
  \newcounter{pipeline} \setcounter{pipeline}{\value{tabmain}}
	\mytabcaption{Potokowe wykonanie rozkazów. W~kolumnach umieszczone są komponenty wykonujące dany krok rozkazu.
	W~wyróżnionej kolumnie można odczytać, że w~czwartym cyklu zegarowym pierwszy rozkaz jest w~trakcie wykonywania kroku MEM, 
	dla drugiego wykonywany jest krok EX, itd}
	\end{center}
	Metoda ta pozwala na ,,równoległe'' wykonanie kilku rozkazów na jednym procesorze, w~przykładzie opisanym w~tabeli \arabic{pipeline}, po upływie 7 cykli
	zostaną wykonane trzy rozkazy. Gdyby rozkazy te były wykonane na jednostce sekwencyjnej, czas ich wykonania byłby ponad dwa razy dłuższy.
\par
%
\indent
	Architektura procesora, która jest uogólnieniem potokowości to \emph{Superskalarność} (ang. \emph{Superscalar}): 
	każdemu krokowi odpowiada co najmniej jeden potok, jednakże występuje redundancja części funkcjonalnych procesora.
	\begin{center}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|} \hline
	Numer 		 & \multicolumn{7}{c|}{\multirow{2}{*}{Stan potoku}} \\
	rozkazu & \multicolumn{7}{c|}{} \\ \hline
	1 & IF & ID & EX & \cellcolor{yellow} MEM & WB & & \\ \hline
	2 & IF & ID & EX & \cellcolor{yellow} MEM & WB & & \\ \hline
	3 & & IF & ID & \cellcolor{yellow} EX & MEM & WB & \\ \hline
	4 & & IF & ID & \cellcolor{yellow} EX & MEM & WB & \\ \hline
	5 & & & IF & \cellcolor{yellow} ID & EX & MEM & WB \\ \hline
	6 & & & IF & \cellcolor{yellow} ID & EX & MEM & WB \\ \hline
	7 & & & & \cellcolor{yellow} IF & ID & EX & MEM \\ \hline
	8 & & & & \cellcolor{yellow} IF & ID & EX & MEM \\ \hline
	9 & & & & \cellcolor{yellow} & IF & ID & EX \\ \hline
	10 & & & & \cellcolor{yellow} & IF & ID & EX \\ \hline \hline
	Cykl zegara & 1 & 2 & 3 & \cellcolor{yellow} 4 & 5 & 6 & 7 \\ \hline
	\end{tabular}
	\mytabcaption{Potokowe wykonanie 10 rozkazów na jednostce superskalarnej o~dwóch potokach rozkazów: rozkazy o~numerach nieparzystych są wykonywane na 
					pierwszej jednostce, zaś rozkazy o~numerach parzystych na drugiej. Analogicznie jak w~tabeli \arabic{pipeline}, wyróżniona
					kolumna odpowiada wykonaniu programu w~czwartym cyklu zegarowym}
	\end{center}
	Jak łatwo zauważyć, superskalarny CPU jest w~stanie przetworzyć nawet wektor instrukcji. Warunkiem koniecznym do osiągnięcia takiego
	wyniku jest brak zależności pomiędzy wynikiem wcześniejszej a~następnej instrukcji.
\par
%
\indent
	Opisane wyżej techniki napotykają jednak na podstawowy problem: w~momencie, gdy bieżącym rozkazem jest skok warunkowy, kolejna wczytana 
	instrukcja nie musi być koniecznie kolejną instrukcją programu. Tak więc, częściowo wykonana instrukcja (lub, w~przypadku jednostek
	superskalarnych, nawet w~pełni wykonane rozkazy) nie powinna wywrzeć wpływu na żaden z~zasobów komputera, 
	a~dodatkowo jest ona niepotrzebnie przetwarzana.
\par
%
\indent
	W~celu zniwelowania niedogodności związanych z~,,nietrafionymi'' skokami warunkowymi, zaczęto stosować technikę 
	\emph{przewidywania skoku} (ang. \emph{branch prediction}): stosowane są heurystyki, które określają prawdopodobny
	wynik instrukcji skoku. Dzięki ich stosowaniu, udaje się w~dużej liczbie przypadków uniknąć niepotrzebnych obliczeń,
	a~wykonywane są te rozkazy, które rzeczywiście są potrzebne do wykonania programu.
	Przewidywanie skoku jest jedną z~technik stosowanych w~mechanizmie zwanym \emph{Wykonaniem spekulatywnym} (ang. \emph{Speculative execution}):
	wykonanie spekulatywne dopuszcza również wykonanie (przy spełnieniu określonych założeń) części programu znajdującego się za skokiem warunkowym,
	ale jeszcze \emph{przed} wykonaniem tego skoku.
\par
%
\newcounter{oooex} \setcounter{oooex}{\value{figmain}}
\indent
	Technika wykonania określonego fragmentu kodu źródłowego jest stosowana również w~mechanizmie \emph{Wykonania poza kolejnością}
	(ang. \emph{Out of Order execution, OoO}): jeśli pewien rozkaz używa wartości rejestru, która została już obliczona, to można go wykonać
	poza kolejnością podaną przez autora programu. Dla sekwencji rozkazów z~rys.~\arabic{oooex}
	można zauważyć, że rozkaz (3) korzysta z~wartości rejestru A3, który jest wyliczony w~(1), jego wykonanie nie ma wpływu na rejestry, z~których 
	korzysta (2), a~więc sekwencja $\langle 1, 3, 2 \rangle $ da po wykonaniu wynik taki sam, jak sekwencja $\langle 1, 2, 3 \rangle $.
	\begin{center}
	\begin{tabular}{l}\\
		(1) {\tt add A1,A2,A3 /* dodaj A1 do A2, wynik zapisz do A3 */ } \\
		(2) {\tt add A1,A4,A5 } \\
		(3) {\tt add A2,A3,A7 } \\
		\\
	\end{tabular}
  \myfigcounter{Wykonanie poza kolejnością}
	\end{center}
\par
%
\indent
	Podczas wykonania programu pewne rejestry procesora są wykorzystywane częściej, zaś inne rzadziej. Aby zwiększyć użycie rzadziej
	używanych rejestrów i~wykonać kolejne rozkazy poza kolejnością, można tymczasowo potraktować nieużywany rejestr jak ten, który miał
	być pierwotnie użyty do wykonania rozkazu (zapisać jego dotychczasową wartość, skopiować wartość z~odpowiedniego rejestru, wykonać instrukcję,
	przywrócić poprzednią wartość tak wykorzystanego rejestru). Taka technika jest zwana 
	\emph{Przemianowaniem rejestrów} (ang. \emph{Register Renaming}).
\par
%
\indent
	Dzięki opisanym wyżej technikom możliwe jest zrównoleglenie wykonania programu (w~stosunku do procesora wykonującego rozkazy sekwencyjnie)
	już na poziomie pojedynczych instrukcji procesora. Stąd też techniki te są określane mianem \emph{instruction level parallelism} (ILP).
	Podstawową zaletą tych technik jest znaczące przyspieszenie działania procesora, jednakże implementacja tych technik w~procesorze pociąga za
	sobą zwiększenie liczby tranzystorów, a~co za tym idzie, zwiększenie temperatury wydzielanej przez CPU.
\par
%
\newcounter{datadep} \setcounter{datadep}{\value{figmain}}
\indent
	Problemem, który jest naturalnie związany z~ILP to zależność od danych (ang. \emph{data dependency}).
	Dotyczy on zachowania oryginalnej chronologii wykonywania rozkazów (zapisu wyników
	ich działania w~procesorze, pamięci i~urządzeniach zewnętrznych). W sekwencji przedstawionej na rys.\arabic{datadep}
	instrukcje (1) i~(2) mogą wyć wykonane w~kolejności $\langle 1,2 \rangle$ jak i~$\langle 2,1 \rangle$, zaś wynik działania instrukcji
	(3) zależy bezpośrednio od wyników działania (1) i~(2). Co więcej, instrukcja (4) nie może być wykonana wcześniej 
	niż po zakończeniu wykonania instrukcji (1), (2) i~(3). Tak więc chronologia wykonania instrukcji (3) i~(4) nie może być zmieniona.
	\begin{center}
	\begin{tabular}{l l}\\
		(1) & {\tt add Y,Z,X} \\
		(2) & {\tt add U,V,T} \\
		(3) & {\tt mult X,T,L /* zapisz iloczyn X}$\times${\tt T do L */} \\
		(4) & {\tt add L,T,L} \\
	\end{tabular}
	\myfigcounter{Ilustracja problemu zależności od danych}
	\end{center}
\par
%
\indent
	W~celu rzeczywistego zrównoleglenia działania programu, w~komputerach pojawiło się więcej procesorów,
	które działały niezależnie od siebie. Procesory były pojedynczymi układami, bądź kilka procesorów umieszczano w~jednym układzie. 
	Pojedynczy procesor w~kości zawierającej kilka jednostek centralnych zwany jest \emph{rdzeniem} (ang. \emph{core}).
	Odpowiednio zaprojektowany program,	który korzysta z~kilku procesorów może przyspieszyć swoje działanie nawet proporcjonalnie do ich liczby,
	na których jest wykonywany.	Takie przyspieszenie działania programu, choć możliwe, jest rzadko spotykane.
	Dobrą ilustracją problemu przyspieszania działania procesora jest prawo Amdahla, opisane w~dalszej części tego dokumentu.
\par
%
\newcounter{flynn} \setcounter{flynn}{\value{tabmain}}
\indent
	Michael J.~Flynn stworzył klasyfikację systemów komputerowych oraz programów (\emph{taksonomia Flynna}), w~której ze względu na liczbę
	strumieni rozkazów oraz danych, wyróżniamy cztery klasy, wymienione w~tabeli \arabic{flynn}.
	Klasy te możemy scharakteryzować w~następujący sposób:
	\begin{itemize}
		\item SISD jest klasą programów wykonywanych sekwencyjnie na maszynie sekwencyjnej;
		\item SIMD odpowiada programom wykonywanym na maszynie superskalarnej lub na procesorach przetwarzających sygnały (DSP);
		\item MISD jest klasą maszyn i~programów, która ma zastosowanie tam, gdzie liczy się minimalizacja błędów;
		\item MIMD odpowiada programom wykonywanym na wielu procesorach.
	\end{itemize}
	\begin{center}
	\centering
	\begin{tabular}{|c|c|c|} \hline
													 & Jeden strumień instrukcji	 & Wiele strumieni instrukcji \\
													 & (\emph{Single Instruction}) & (\emph{Multiple Instruction}) \\\hline
			Jeden                &     												 &      \\
			strumień danych      &  SISD										   & MISD 			\\
			(\emph{Single Data}) &                             & \\\hline
			Wiele                &     												 &      \\
			strumieni danych     & SIMD                        & MIMD \\
			(\emph{Multiple Data}) & 										 & 			\\\hline
	\end{tabular} \nopagebreak
	\mytabcaption{Taksonomia Flynna}
	\end{center}
\par
\indent
	Komputery sklasyfikowane jako MIMD, ze względu na rodzaj komunikacji pomiędzy procesorami, można podzielić na dwie podklasy:
	\begin{itemize}
		\item o~rozproszonej pamięci: każdy procesor posiada przyporządkowaną
			dla niego pamięć. W~takim układzie procesory wraz z~pamięcią im dedykowaną mogą być traktowane jako oddzielne komputery, 
			zaś komunikacja między nimi przebiega po pewnej ustalonej ścieżce (np. za pomocą połączenia sieciowego).
			Taka architektura systemu komputerowego nazywana jest \emph{wieloprocesorowością asymetryczną} (ang. \emph{asymmetric multiprocessing, AMP}),
			zaś najczęściej jest spotykana w~systemach rozproszonych czy klastrach.
		\item o~dzielonej pamięci: wszystkie procesory korzystają z~tej samej pamięci.
	\end{itemize}
	W~systemach, w~których wszystkie procesory korzystają z~jednej, dzielonej pamięci, komunikacja pomiędzy procesorami odbywa się za jej pomocą.
	Można wyróżnić dwie najczęściej stosowane architektury:
	\begin{itemize}
		\item nadrzędna jednostka/jednostka podrzędna (ang. \emph{master/slave}): jeden z~procesorów posiada uprzywilejowany dostęp do pamięci (master).
			Na tym procesorze są wykonywane najważniejsze dla programu zadania (np. \emph{jądro systemu operacyjnego}, ang. \emph{kernel}),
			zaś pozostałe jednostki centralne posiadają ograniczony dostęp do pamięci (slave), jak również do innych zasobów komputera 
			(np. aplikacje użytkownika systemu operacyjnego).
			Jeśli jednostka podrzędna potrzebuje wykonania pewnego działania, które może być wykonane jedynie przez jednostkę nadrzędną, musi w~tym celu
			przesłać żądanie do jednostki typu master. Taka architektura posiada dwie zasadnicze wady:
			\begin{itemize}
				\item błąd (usterka) jednostki uprzywilejowanej powoduje zerwanie działania programu (systemu operacyjnego);
				\item jednostka typu master może stać się \emph{wąskim gardłem} (ang. \emph{bottleneck}) programu (systemu operacyjnego),
					gdy ilość żądań wykonania specyficznych dla niej operacji przekroczy pewien zależny od niej samej próg, lub też gdy pewne
					operacje będą wykonywane w~sposób nieefektywny.
			\end{itemize}
		\item \emph{SMP} (ang. \emph{symmetric multiprocessing}): wszystkie procesory w~systemie komputerowym posiadają identyczne przywileje
			dostępu do pamięci oraz innych jego zasobów. Dzięki temu, możliwe jest wykonywanie jednej aplikacji na wielu procesorach jednocześnie,
			możliwa jest również ,,wędrówka'' wydzielonych części aplikacji po wszystkich dostępnych w~komputerze procesorach.
	\end{itemize}
\par
%
\indent
	Opisane powyżej techniki stosowane w~architekturach procesorów, jak również same architektury systemów operacyjnych, kładą nacisk na
	zrównoleglenie wykonywania programów. Głównym wyzwaniem, jakie stoi przed programistą, jest takie zaprojektowanie aplikacji,
	aby można było ją wykonać równolegle na jak największej liczbie procesorów, co przełoży się na krótszy czas wykonania.
	Aplikacja będzie komunikować się ze światem zewnętrznym, a~w~szczególności z~użytkownikiem o~wiele sprawniej, niż ta sama aplikacja,
	ale zaprojektowana w~sposób sekwencyjny.
\par
%
\indent
	Można zauważyć, że wzrost mocy obliczeniowej maszyn wieloprocesorowych (wielordzeniowych) w~stosunku do maszyn klasy SISD (SIMD) jest
	analogiczny do wzrostu mocy obliczeniowej procesora posiadającego architekturę ILP do procesora posiadającego architekturę sekwencyjną.
	Jednakże, aby wykorzystać potencjał architektur równoległych,
	zarówno ILP jak i~MIMD wymagają odpowiednio zaprojektowanych i~zaprogramowanych aplikacji.
\par
%
\subsection{Pamięć}
\indent
	Pamięć w~systemie komputerowym możemy podzielić na dwa rodzaje: ulotną i~trwałą. Informacje znajdujące się w~pamięci ulotnej
	nie będą odzyskane po wyłączeniu i~ponownym włączeniu komputera. Można wyróżnić dwa rodzaje pamięci ulotnej:
	\begin{itemize}
		\item wewnętrzna: procesor komunikuje się z~nią bez pośrednictwa szyny systemowej. Jest taktowana tą samą częstotliwością, co CPU
			(lub bardzo do niej zbliżoną). Pamięciami tego rodzaju są:
			\begin{itemize}
				\item rejestry procesora;
				\item pamięć podręczna (ang \emph{cache}), często wielopoziomowa.
			\end{itemize}
		\item Systemowa (operacyjna): szyna systemowa pośredniczy podczas operacji odczytu/zapisu do pamięci tego rodzaju. Ta pamięć jest zwana
			pamięcią główną komputera (ang. \emph{main memory, primary memory}), a~ponieważ dostęp do każdej komórki tej pamięci
			w~każdym momencie działania systemu komputerowego jest możliwy, zwana jest również pamięcią o~dostępie swobodnym
			(ang. \emph{random access memory, RAM}).
	\end{itemize}
	Z~punktu widzenia procesora, pamięć trwała jest pamięcią ,,za'' szyną systemową, za wyjątkiem pamięci stałej (ang. \emph{read only memory, ROM}),
	nie znajduje się ona nawet na płycie głównej, na której znajduje się jednostka centralna, dlatego pamięci tego rodzaju zwane są 
	zewnętrznymi. O~ile pamięć główna jest uprzywilejowanym urządzeniem o~najszybszym dostępie, o~tyle dostęp do pamięci
	zewnętrznych jest o~wiele wolniejszy. Do trwałych pamięci zewnętrznych zaliczyć można następujące urządzenia:
	\begin{itemize}
		\item dyski magnetyczne (dyskietki, dyski twarde, SSD, pamięci typu Flash);
		\item płyty CD, DVD, BD;
		\item taśmy magnetyczne.
	\end{itemize}
\par
%
\indent
	%Można zauważyć, że ,,murem'' oddzielającym procesor od pamięci (za wyjątkiem pamięci wewnętrznej) jest szyna systemowa.
	W~obecnych komputerach szyny systemowe są taktowane niższymi częstotliwościami (nawet kilkakrotnie), niż sam procesor.
	Także sama pamięć RAM może być taktowana niższą od wymienionych wcześniej częstotliwością.
	Taka dysproporcja w~taktowaniu części systemu komputerowego może prowadzić do przestojów w~pracy procesora: nie może wykonać żadnego działania,
	ponieważ nie ma kolejnych instrukcji programu. Rosnąca dysproporcja w~taktowaniu procesorów i~pamięci jest zwana \emph{murem pamięciowym}
	(ang. \emph{memory wall}, \cite{wulf}).
\par
%
\indent
	Pamięć podręczna jest bardzo ważną częścią pamięci ulotnej: to z~tej pamięci (a~dokładniej: z~pamięci pierwszego poziomu) procesor
	może pobierać pojedyncze bajty i~tylko na tej pamięci może on wykonywać operacje odczytu/zapisu. 
	Z~pamięci RAM dane pobierane są do pamięci cache (do najwyższego poziomu cache\dywiz u) w~paczkach o~określonej wielkości (np. 32 bajty),
	dzięki czemu zmniejsza się liczba żądań dostępu pamięci podręcznej (widzianej przez szynę danych jako procesor) do pamięci operacyjnej.
	Takie rozwiązanie pociąga za sobą problem zgodności danych: jeśli procesor zmieni zawartość pewnej komórki pamięci,
	to zawartość odpowiadającej jej komórki w~pamięci operacyjnej powinna być taka sama w~momencie odczytu dokonywanego przez inny procesor
	znajdujący się w~systemie. Problem ten można rozwiązać na dwa sposoby:
	\begin{itemize}
		\item jeśli zgłaszane jest żądanie dostępu do komórki przez rdzeń znajdujący się w~tym samym układzie, wystarczy wymienić wartość komórki
			tylko we współdzielonej pamięci podręcznej, a~następnie przesłać ją do cache\dywiz u~pierwszego poziomu, do którego dostęp posiada
			rdzeń, który zgłosił żądanie. Zawartość pamięci operacyjnej zostanie uaktualniona \emph{później}.
		\item Jeśli dostępu do komórki zażądał inny procesor, wówczas należy przesłać zawartość komórki do pamięci RAM.
	\end{itemize}
	Oczywiście, jeśli następuje zmiana zawartości pamięci podręcznej, zawartość zmienionej komórki musi zostać przesłana do pamięci operacyjnej
	(jest to sytuacja, która została określona jako ,,później'').
\par
%
\indent
	Dokładny i~wyczerpujący opis pamięci stosowanych we współczesnych komputerach można znaleźć w~\cite{jacob}.
\par
%
\subsection{Urządzenia zewnętrzne}
\indent
	Urządzenia zewnętrzne, znane również jako \emph{peryferia}, \emph{urządzenia wejścia\dywiz wyjścia}, \emph{I/O} (\emph{ang. Input/Output}),
	to, oprócz pamięci trwałych, także urządzenia do komunikacji komputera ze światem zewnętrznym. 
	Można podzielić je według właściwości odczytu/zapisu na trzy grupy:
	\begin{itemize}
		\item{tylko odczyt danych, np.} klawiatura, mysz, 
		\item{tylko zapis, np.} wyświetlacz,
		\item{odczyt i~zapis, np.} karta sieciowa, graficzna, dźwiękowa, \ldots
	\end{itemize}
\par
%
\indent
	Komunikacja procesora z~peryferiami odbywa się poprzez szynę systemową.
\par
%
\newpage
\section{System operacyjny}
%
\label{sec:system}
\subsection{Wstęp}
\indent
	System operacyjny (ang. \emph{operating system, OS}, zwany dalej \emph{systemem}) jest programem, 
	który kontroluje wykonanie aplikacji użytkownika (programów),
	może być postrzegany jako pośrednik (interfejs) pomiędzy programem a~sprzętem (systemem komputerowym), na którym jest wykonywany.
	Najważniejszą zyskiem z~używania systemu jest możliwość uruchomienia programu napisanego dla jednego OS, który będzie działać na różnych systemach komputerowych.
\par
%
\indent
	Programy użytkownika wykonywane pod kontrolą systemu operacyjnego mogą być proste (np. program do zliczania słów w~pliku tekstowym)
	lub złożone (program do obsługi transakcji bankowych). OS musi zatem udostępniać pewną abstrakcję systemu komputerowego dostarczaną dla użytkownika,
  dzięki której możliwe będzie korzystanie z~zasobów komputera. Abstrakcja ta jest zrealizowana jako zbiór \emph{usług} (ang. \emph{services}) systemu operacyjnego.
  O~ile wskazane jest, aby użytkownik nie miał dostępu do wszystkich zasobów systemu operacyjnego, o~tyle usługi OS muszą mieć taki dostęp.
  Zbiór usług systemu jest zwany \emph{jądrem} (ang. \emph{kernel}), zaś tryb pracy systemu z~dostępem do wszystkich zasobów OS zwany jest
  \emph{przestrzenią jądra} (ang. \emph{kernel space}).
\par
%
\indent
  Zdecydowana większość obecnych systemów operacyjnych to systemy wielozadaniowe z~\emph{wywłaszczaniem} (ang. \emph{pre\dywiz emptive multitasking operating system})
  oraz \emph{zarządzaniem pamięcią} (ang. \emph{memory management}). Dlatego też w~dalszej części tego rozdziału opisane będą fragmenty takich właśnie systemów.
\par
%
\indent
  Mechanizm wywłaszczania można określić jako zatrzymanie bieżącego programu oraz zapis jego stanu.
\par
%
\indent
  Zarządzanie pamięcią osobno dla każdego programu pozwala na bezpieczne zarządzanie programami: jeśli jeden z~nich będzie próbował wykonać dowolną operację
  poza swoją \emph{przestrzenią adresową} (ang. \emph{address space}), system będzie mógł zareagować na taką próbę oraz poinformować odpowiedzialny za nią program
  o~jego nieprawidłowym działaniu.
\par
%
\indent
  Jedną z~ważnych usług systemu operacyjnego jest wytworzenie i~zarządzanie \emph{zadaniem} (ang. \emph{task}), zwanym również \emph{procesem}
  (ang. \emph{process}). Każdy proces jest reprezentowany w~systemie przez \emph{blok kontrolny procesu} (ang. \emph{Process Control Block}, PCB).
  Zawiera on wszystkie informacje o~odpowiadającym mu procesie, m. in.:
  \begin{itemize}
    \item unikalny identyfikator procesu;
    \item kontekst wykonania procesu, tj. stan rejestrów procesora, licznik rozkazów, wskaźnik stosu;
    \item informacje o~pamięci przydzielonej dla procesu (jego przestrzeni adresowej);
    \item statystyki procesu: ilość zużytego czasu procesora, ilość wykonanych operacji wywłaszczenia, \ldots
    \item priorytet procesu;
    \item wskaźnik na następny PCB.
  \end{itemize}
  Jest to struktura zawierająca komplet informacji o~odpowiadającym jej zadaniu, dostępna jedynie z~poziomu przestrzeni jądra.
  Dla przykładu, jądro systemu Linux w~wersji 3.1 wytwarza PCB o~wielkości ok. 1,7 KiB.
\par
%
\indent
  Procesy, jakie może uruchomić użytkownik, działać będą w~\emph{przestrzeni użytkownika} (ang. \emph{user space}).
  Każdy program działający w~systemie operacyjnym składa się z~co najmniej jednego procesu.
\par
%
\indent
	Jądro systemu to jego podstawa, która jest odpowiedzialna za zarządzanie jego usługami, jak również zasobami, m. in. pamięcią, I/O,
	przydzielaniem czasu procesora poszczególnym procesom. Instrukcje procesu jądra wykonywane są w~przestrzeni jądra. Dzięki temu,
	mają one dostęp do wszystkich zasobów systemu komputera i~mogą je dowolnie zmieniać. Dlatego też procesy uruchamiane w~przestrzeni
	jądra muszą być zaprojektowane zgodnie ze wszystkimi wymaganiami stawianymi danemu systemowi operacyjnemu, wraz z~podstawowym wymaganiem:
	muszą one być \emph{niezawodne}, gdyż w~razie wystąpienia poważnego błędu w~trakcie wykonywania programu uruchomionego w~przestrzeni jądra,
	działanie wszystkich aplikacji w~systemie zostanie zaburzone, a~w~konsekwencji może doprowadzić to do unicestwienia całego systemu operacyjnego.
\par
%
\subsection{Procesy}
\indent
  Jak wspomniano wyżej, każdy proces to dla systemu operacyjnego odpowiadający mu PCB, który jest analizowany przez system, a~następnie
  zostają mu udostępnione odpowiednie zasoby komputera. W~przypadku zakończenia działania procesu, system podejmuje akcje związane z~usunięciem zadania.
\par
%
\indent
  Każdy proces potrzebuje do działania co najmniej dwóch zasobów systemu operacyjnego, a~są nimi:
  \begin{enumerate}
    \item Czas procesora: czas ten jest porcjowany dla każdego procesu; system daje do dyspozycji zadania \emph{plasterek czasu} (ang. \emph{time slice}),
      po upływie którego (o~ile proces wcześniej nie oddał sterowania systemowi) proces będzie wywłaszczony. Do ustalenia, który proces ma otrzymać następny plasterek,
      stosuje się polityki długo\dywiz ~oraz krótkoterminowe, realizowane przez odpowiadających im \emph{planistów} (ang. \emph{schedulers}).
    \item Pamięć RAM: każdy proces działa w~swojej przestrzeni adresowej. Proces używa jej jak liniowej pamięci, począwszy od adresu o~adresie 0.
      System przelicza każde odwołanie do odpowiedniej komórki na odwołanie do rzeczywistej komórki pamięci, a~następnie sprawdza, czy komórka taka znajduje się
      w~przestrzeni adresowej tego procesu i~w~zależności od wyniku tego sprawdzenia podejmuje akcje zgodne ze swoją polityką. Ponieważ takie sprawdzanie powoduje spory narzut
      czasowy na działanie procesu i~systemu, w~celu jego usprawnienia powstały mechanizmy mające usprawnić zarządzanie pamięcią -- zarówno od strony sprzętowej
      (mechanizmy ochrony pamięci), jak i~programowej (udogodnienia na poziomie kompilacji).
  \end{enumerate}
  Oprócz tych dwóch zasobów, system z~reguły daje do dyspozycji procesu trzy urządzenia: standardowe wejście, wyjście oraz wyjście błędów.
\par
%
\indent
  Programy, a~więc i~odpowiadające im procesy, można podzielić na dwie zasadnicze grupy: interaktywne i~nieinteraktywne.
  Procesy z~pierwszej grupy najczęściej oczekują na reakcję użytkownika lub wystąpienie określonego zdarzenia w~urządzeniu systemowym,
  zaś procesy z~drugiej grupy nie potrzebują do swojego działania żadnej interakcji ze światem zewnętrznym.
\par
%
\indent
  Zarządzanie czasem procesora jest przede wszystkim powinnością planisty krótkoterminowego (ang. \emph{short--term scheduler}),
  zaś planista długoterminowy odpowiada za wybór procesów, które będą wczytane z~pamięci zewnętrznej do RAM. Planista długoterminowy
  jest uruchamiany rzadko w~porównaniu do uruchamiania planisty krótkoterminowego. Stąd, planista krótkoterminowy musi być wydajny.
  Jądro posiada także \emph{dyspozytora}, który odpowiada za wywłaszczanie procesów oraz przekazywanie do nich sterowania.
\par
%
\indent
  Zarządzanie pamięcią procesu jest zadaniem pracochłonnym: podczas przełączania pomiędzy dwoma procesami następuje zmiana przestrzeni adresowej pierwszego procesu
  na przestrzeń adresową drugiego. Ze względu na 
\par
%
\subsection{Wątki}
\indent
	Rozwiązaniem kosztownego problemu przełączania pomiędzy przestrzeniami adresowymi procesów jest zastosowanie \emph{wątków} (ang. \emph{threads}).
	Wątki w~ramach jednego procesu posiadają wspólną przestrzeń adresową, sumaryczny czas ich wykonania jest równy czasowi przydzielonemu dla 
	procesu, w~ramach którego są wykonywane. Przełączanie pomiędzy nimi również pociąga za sobą poniesienie kosztów czasowych, są one jednak
	o~wiele niższe niż te, które należało by ponieść w~wypadku przełączania sterowania pomiędzy procesami. Z~powodu mniejszego narzutu czasowego,
	związanego z~przełączaniem pomiędzy wątkami, nazywane są one również \emph{procesami wagi lekkiej} (ang. \emph{lightweight processes}).
	Wraz z~niewątpliwą oszczędnością czasu podczas przełączania pomiędzy wątkami, z~powodu używania przez wątki tej samej przestrzeni adresowej,
	następuje utrata izolacji przestrzeni adresowej pomiędzy nimi. Może się to wiązać z~utratą bezpieczeństwa danych używanych przez dany wątek,
	dlatego też, podczas projektowania aplikacji należy dokonać takiego podziału zadań na procesy i~wątki, aby zachować zakładaną ochronę danych.
\par
%
\subsection{Procesy i~wątki w~systemie Linux}
\indent
\par
%
\newpage
\section{Opis rozwiązania}
\label{sec:solution}
\subsection{Wstęp}
\indent 
  Biblioteka \code{libmixed} spełnia wymagania wymienione w~rozdziale \ref{sec:target}, za wyjątkiem warunku \ref{enm:timesch}:
  istnieje komponent biblioteki odpowiedzialny za szeregowanie włókien, jednak \code{libmixed} nie kontroluje czasu wykonania pojedynczego włókna.
\par
\indent
  Każda składowa biblioteki działa w~jednej z~dwóch warstw:
  \begin{enumerate}
    \item Nadzorczej: każdy byt tej warstwy ma za zadanie obsługę włókna (uruchomienie, komunikacja pomiędzy włóknami, udostępnienie
      zasobów I/O).
    \item Włókna: są to udogodnienia biblioteki dostępne bezpośrednio z~poziomu włókna, a~więc dostępne dla użytkownika \code{libmixed}.
  \end{enumerate}
\par
\begin{center}
  \myownfigure{libmixedoverview}{libmixedOverview.png}{Zależności pomiędzy klasami biblioteki \code{libmixed}}{.7}
\end{center}
\indent
  Rysunek \arabic{libmixedoverview} przedstawia zależności pomiędzy klasami biblioteki \code{libmixed}.
  Do warstwy nadzorczej należą klasy:
  \begin{itemize}
    \item \code{master}: zarządza \emph{robotnikami} (obiektami klasy \code{worker}), pośredniczy w~komunikacji między włóknami;
    \item \code{worker}: zarządza obsługą przydzielonych mu włókien, odpowiada za poprawne wykonanie operacji I/O (\function{read}, \function{write}, \ldots);
    \item \code{scheduler}: odpowiada za szeregowanie włókien;
    \item \code{epoller}: rejestruje wystąpienie zdarzeń powiązanych z~obserwowanymi urządzeniami I/O;
    \item \code{message\_queue}: udostępnia mechanizm służący do wymiany wiadomości pomiędzy włóknami.
  \end{itemize}
  Do warstwy włókna należy klasa \code{fiber}, która udostępnia użytkownikowi wszystkie mechanizmy oraz udogodnienia biblioteki \code{libmixed} w~postaci
  zwartego interfejsu.
\par
\indent
  Rysunek przedstawia zależności pomiędzy klasami biblioteki. Z~punktu widzenia użytkownika, najważniejsze dwie klasy \arabic{libmixedoverview} to:
  \begin{enumerate}
    \item \code{fiber}: baza każdego włókna, użytkownik definiuje (nadpisując funkcję \function{fiber\dcolon go}) jej działanie.
    \item \code{master}: każdy obiekt tej klasy jest tożsamy z~całym podsystemem zarządzającym włóknami. W~ramach jednego procesu możliwe jest działanie wielu
      obiektów tej klasy.
  \end{enumerate}
\par
%
\newpage
\subsection{Koprocedury -- klasa \code{coroutine}}
\label{sec:coroutine}
%
\indent
Koprocedura jest uogólnieniem pojęcia procedury, co pokazuje Tabela \arabic{tabmain}.
    \begin{center}
    \centering
    \begin{tabular}{|l|l|} \hline
      \multicolumn{1}{|c|}{Procedura} & \multicolumn{1}{c|}{Koprocedura} \\ \hline
      jeden punkt wejścia & jeden punkt wejścia \\ \hline
      \parbox[t]{6cm}{ brak możliwości kontynuacji działania po wyjściu z~procedury } & \parbox[t]{6cm}{możliwość kontynuacji działania po wyjściu z~koprocedury } \\ \hline
      \parbox[t]{6cm}{jednorazowe przekazanie wyniku obliczeń} & \parbox[t]{6cm}{przekazanie częściowego wyniku obliczeń} \\ \hline
      współdzielony stos wywołań & własny stos wywołań \\ \hline
      współdzielony kontekst wykonania & własny kontekst wykonania \\ \hline
      współdzielony czas działania & współdzielony czas działania \\ \hline
    \end{tabular}
    	\mytabcaption{Porównanie procedury i~koprocedury}
    \end{center}
  klasa \code{coroutine} jest implementacją koprocedury. Jest ona klasą bazową dla klasy \code{fiber},
  a~więc każde włókno jest koprocedurą.
  \myownfigure{Coroutine}{Coroutine.png}{Klasa coroutine - implementacja koprocedury}{.7}
	Obsługa kontekstu wykonania koprocedury realizowana jest przy użyciu funkcji
	\code{getcontext()}/\code{swapcontext()}, dostępnych w~każdym systemie zgodnym ze specyfikacją POSIX lub Single Unix Specification (SUS).
\par
%
\indent
  Klasa \code{coroutine} udostępnia użytkownikowi następujące funkcje:
  \begin{itemize}
    \item \function{init}: funkcja inicjalizująca koprocedurę. Każdy obiekt klasy \code{coroutine} musi być zainicjalizowany za pomocą tej funkcji,
      gdyż w~przeciwnym wypadku nie zostanie utworzony stos wywołań dla koprocedury, a~co za tym idzie -- działanie programu będzie przerwane.
    \item Funkcja \function{run} odpowiada za przełączenie bieżącego kontekstu wykonania na kontekst koprocedury. 
      Po przełączeniu kontekstu wykonywana jest funkcja \function{start} -- już w~nowym kontekście i~ze stosem wywołań koprocedury. Funkcja \function{go}
      \emph{powinna} być wywołana z~funkcji \function{start}. Funkcja \function{start} ma służyć użytkownikowi do przygotowania przed uruchomieniem koprocedury,
      zaś funkcja~\function{go} jest jej \emph{ciałem}. Celem funkcji \function{start} jest także wykrycie zakończenia działania koprocedury.
      Dodatkowo, w~ciele tej funkcji można umieścić mechanizm detekcji oraz propagacji wyjątków.
    \item Funkcja \function{yield} służy do przekazania częściowego wyniku działania koprocedury. Do użytkownika należy sposób, w~jaki wynik jest przekazywany,
      gdyż \function{yield} jedynie przełącza kontekst koprocedury na kontekst wywołujący koprocedurę.
  \end{itemize}
\par
%
\subsection{Klasa bazowa włókna -- \code{fiber}}
\label{sec:fibers}
    \myownfigure{Fiber}{Fiber.png}{Klasa fiber - implementacja włókna}{.7}
%
\indent
  \code{fiber} jest klasą bazową dla włókien, które użytkownik zgłasza zarządcy (obiektowi klasy \code{master}) do uruchomienia.
  Posiada ona następujące udogodnienia:
  \begin{enumerate}
    \item Komunikacja: wymiana wiadomości z~innymi włóknami. Po wytworzeniu wiadomości, można ją przesłać do odbiorcy za pomocą nieblokującej funkcji \function{send\_message}.
    Do odbioru wiadomości służą funkcje \linebreak \function{receive\_message} (blokująca) oraz \function{receive\_message\_nonblock} (nieblokująca).
    \item Wytworzenie włókna: funkcja \function{spawn} umożliwia uruchomienie włókna w~przestrzeni włókien bieżącego zarządcy (obiektu klasy \code{master}).
    \item Obsługa wejścia-wyjścia: włókno udostępnia następujące udogodnienia:
      \begin{enumerate}
        \item blokujące operacje odczytu (\function{do\_read}) oraz zapisu (\function{do\_write});
        \item podstawową obsługę gniazd sieciowych: funkcja \function{do\_connect} odpowiada systemowej operacji \function{connect}, a~funkcje \function{do\_accept} 
          \linebreak i~\function{do\_close} odpowiadają operacjom \function{accept} oraz \function{close}. Wywołanie każdej funkcji blokuje wykonanie włókna do momentu wystąpienia  
          zdarzenia związanego z~podanym deskryptorem.
      \end{enumerate}
    \item Przekazanie sterowania z~włókna do zarządcy -- funkcja \function{yield}, dziedziczona z~klasy \code{coroutine}.
  \end{enumerate}
  Należy mieć na uwadze, że wymienione funkcje są blokujące jedynie dla wywołującego je włókna, praca robotnika (obiektu klasy \code{worker}, właściciela włókna) nie jest wstrzymywana.
\par
\indent
  Każde włókno posiada bufor używany podczas zapisu/odczytu do i~z~I/O. W~bieżącej implementacji jest on kolekcją standardową klasy \code{vector<char>},
  bezpośredni dostęp do bufora (dla włókna) zapewnia pole \code{rw\_buffer}, zaś funkcje \function{set\_last\_read} oraz \function{set\_last\_write} 
  informują o~ilości bajtów odczytanych/zapisanych podczas ostatnio wykonanej operacji odczytu/zapisu.
  Oprócz podanych wyżej funkcji, każde włókno posiada zestaw funkcji używanych przez zarządzające nim obiekty biblioteki:
  \begin{enumerate}
    \item Do ustawienia bieżącego stanu służy funkcja \function{set\_state}, a~\function{get\_state} informuje o~bieżącym stanie włókna.
    Włókno, ze względu na wykonywane operacje, znajduje się w~jednym ze stanów:
    \begin{itemize}
      \item \code{READY}: włókno gotowe do pracy;
      \item \code{FINISHED}: włókno zakończyło działanie;
      \item \code{BLOCKED\_FOR\_READ}: włókno zablokowane podczas próby odczytu z~I/O;
      \item \code{BLOCKED\_FOR\_WRITE}:  włókno zablokowane podczas próby zapisu \linebreak do I/O;
      \item \code{BLOCKED\_FOR\_ACCEPT}:  włókno zablokowane podczas operacji \code{accept};
      \item \code{BLOCKED\_FOR\_CONNECT}:  włókno zablokowane podczas operacji \code{connect};
      \item \code{BLOCKED\_FOR\_MESSAGE}:  włókno oczekuje na nadejście wiadomości.
    \end{itemize}
    \item Funkcja \function{set\_owner} służy do ustawienia pola \code{owner}, które jest wskaźnikiem na obiekt klasy \code{worker} -- robotnika 
    zarządzającego włóknem. Pole to jest używane przez funkcje udostępnione dla użytkownika, a~odpowiedzialne za komunikację z~innymi włóknami oraz dostęp do I/O.
  \end{enumerate}
\par
\indent
  \myownfigure{LibcoroStates}{LibcoroStates.png}{Stany włókna oraz dozwolone przejścia pomiędzy nimi}{.55}
\par
\subsection{Moduł \code{message\_queues}}
\label{sec:messagequeues}
    \myownfigure{MessageQueuesOverview}{MessageQueuesOverview.png}{Moduł \code{message\_queues} -- klasy i~zależności pomiędzy nimi}{.7}
\indent
  Moduł \code{message\_queues} udostępnia użytkownikowi podstawową klasę \code{message} oraz dwie klasy pochodne: \code{service\_message} oraz
  \code{fiber\_message}, które służą do wymiany wiadomości odpowiednio pomiędzy zarządcami oraz włóknami. Dwa pola klasy \code{message}:
  \code{prev} oraz \code{next}, są wykorzystywane przez obiekt klasy \code{private\_list}.
\par
    \myownfigure{MessageQueue}{MessageQueue.png}{Klasa \code{message\_queue}}{.7}
\indent
  Obiekt klasy \code{message\_queue} zawiera dwie nieblokujące listy komunikatów, które służą do wymiany wiadomości
  pomiędzy dwoma wątkami. Dla łatwej identyfikacji wątków, wątek A~został nazwany \code{master}, zaś wątek B~-- \code{slave},
  jednak są one traktowane jako dwa równorzędne byty. Lista \code{master\_queue} służy do komunikacji \code{slave}$\to$\code{master},
  a~lista \code{slave\_queue} do \code{master}$\to$\code{slave}.
  Tak więc \code{message\_queue} implementuje mechanizm \emph{half\dywiz duplex}, znany z~potoków,
  udostępnianych przez systemy uniksowe.
\par
    \myownfigure{PrivateList}{PrivateList.png}{Klasa \code{private\_list} -- nieblokująca lista dwukierunkowa, używana jako jednokierunkowy kanał do przesyłania wiadomości}{.7}
\indent
  Obiekt klasy \code{private\_list} jest listą dwukierunkową. Dane wkładane do niej nie są buforowane,
  jej rozmiar jest zależny jedynie od ilości dostępnej pamięci. Podczas wkładania lub wyciągania wiadomości z~listy nie są stosowane żadne mechanizmy
  synchronizacji międzywątkowej. Użytkownik tej listy ma do dyspozycji dwie funkcje:
  \begin{enumerate}
    \item Funkcja \function{push} służy do wkładania nowego elementu do listy. Jej wywołanie zawsze jest zakończone sukcesem.
    \item Funkcja \function{top} służy do wyjmowania elementu z~listy -- \emph{głowy} listy. Jeśli lista zawiera co najmniej jeden element, operacja się
    powiedzie (wynik wywołania -- \code{true}), w~przeciwnym wypadku wynikiem wywołania funkcji jest \code{false}.
  \end{enumerate}
  Żadna z~tych funkcji nie wykonuje jakiegokolwiek wywołania systemowego.
\par
\indent
  Każdy element listy, oprócz pól \code{prev} i~\code{next}, posiada również pole \code{used}, które jest używane do stwierdzenia, czy dany element był już
  użyty (\code{true}), czy jest gotowy do użycia (\code{false}).
  Lista posiada zawsze co najmniej jeden element, który jest jej \emph{głową} (\code{head}).
  Lista posiada również wiadomość o~ostatnim elemencie, \emph{wartowniku} (\code{guard}).
\par
\indent
  Funkcja \code{push( in m )} wykonuje następujące operacje:
  \begin{enumerate}
    \item \code{m->prev} $\gets$ \code{guard};
    \item \code{guard->next} $\gets$ \code{m};
    \item \code{guard} $\gets$ \code{m}.
  \end{enumerate}
\par
  \myownfigure{PrivateListPush}{PrivateListPush.png}{Operacja \function{push}}{.7}
\indent
  Implementacja funkcji \code{pop( out m )} jest bardziej skomplikowana:\\
  Czy można użyć \code{head}?
  \begin{enumerate}
    \item TAK -- \code{m}$\gets$\code{head}
    \begin{enumerate}
      \item Czy \code{head->next}$\neq$\code{0}?
      \item TAK -- \code{head}$\gets$\code{head->next}, \code{head->prev->next}$\gets$\code{0}, \code{head->prev}$\gets$\code{0}.
      \item \code{return true}.
    \end{enumerate}
    \item NIE -- Czy \code{head->next}$\neq$\code{0}?
    \begin{enumerate}
      \item TAK -- \code{head}$\gets$\code{head->next}, \code{head->prev->next}$\gets$\code{0}, \code{head->prev}$\gets$\code{0}.
      \item \code{head->used}$\gets$\code{true}, \code{return true}.
      \item NIE -- \code{return false}.
    \end{enumerate}
  \end{enumerate}
\par
  \myownfigure{PrivateListPop1}{PrivateListPop1.png}{Operacja \function{pop} -- pierwsza gałąź algorytmu}{.7}
  \myownfigure{PrivateListPop2}{PrivateListPop2.png}{Operacja \function{pop} -- druga gałąź algorytmu}{.7}
\indent
  Czy powyższa implementacja jest poprawna?
  \begin{enumerate}
    \item Gdy lista jest używana sekwencyjnie, każdy ciąg operacji \function{push} i~\function{pop} nie zaburza wzajemnego położenia głowy i~wartownika (stan \emph{stabilny} listy).
    \item Podczas operacji \function{push} może wystąpić przeplot z~wątkiem wykonującym na tej samej liście operację \function{pop}. 
    Gdy nowa wiadomość nie jest widoczna (rys. \arabic{PrivateListPush}),
    dowolny przeplot obydwu funkcji nie zaburza stanu stabilnego listy. Jedyna możliwość zaburzenia stanu stabilnego może wystąpić w~następującym scenariuszu:
      \begin{center}
      \centering
      \begin{tabular}{|c|c|c|c|} \hline
        Wątek               & Operacja                         & \code{head} & \code{guard} \\ \hline
        A (\function{push}) & \code{guard->next} $\gets$ \code{b} & \code{a} & \code{a} \\ \hline
        B (\function{pop})  & \code{head}$\gets$\code{b}          & \code{b} & \code{a} \\
                            & \code{b->prev->next}$\gets$\code{0} & \code{b} & \code{a} \\
                            & \code{b->prev}$\gets$\code{0}       & \code{b} & \code{a} \\ \hline
        A                   & \code{guard}$\gets$\code{b}         & \code{b} & \code{b} \\ \hline
      \end{tabular}
      	\mytabcaption{Przeplot zaburzający stan stabilny listy}
      \label{tab:stableestate}
      \end{center}
    Jak łatwo zauważyć, zaburzenie to jest chwilowe, a~po zakończeniu wywołań funkcji w~przeplatających się wątkach lista wraca do stanu stabilnego. 
    Każde kolejne wywołanie funkcji \function{pop} przy zablokowanym wywołaniu \function{push}
    nie zmieni żadnego dowiązania w~liście, gdyż element \code{b}~nie ma następnika.
    \item Jeśli wykonanie operacji \function{pop} zostanie przerwane i~nastąpi przeplot z~funkcją \function{push}, która działa na tej samej liście,
    to każdy taki przeplot jest bezpieczny:
    \begin{enumerate}
      \item każdy przeplot operacji obu funkcji zachowuje stan stabilny listy;
      \item każda operacja wykonywana w~\function{pop} dotyczy \emph{lewej strony} elementu listy (informacje dotyczące poprzednika), zaś
      operacje funkcji \function{push} dotyczą \emph{prawej strony} elementu.
    \end{enumerate}
  \end{enumerate}
\par
\indent
  Czy jeszcze jedna implementacja listy dwukierunkowej jest potrzebna, skoro biblioteka standardowa
  oferuje gotową implementację list dwukierunkowych? Odpowiedź na to pytanie jest oczywista: tak, ponieważ listy
  udostępnione przez bibliotekę standardową mogą być używane przez co najwyżej jeden wątek w~danej chwili.
\par
%
\subsection{Klasa \code{scheduler}}
\myownfigure{Scheduler}{Scheduler.png}{\code{scheduler} -- planista włókien}{.7}
\indent
  Rysunek \arabic{Scheduler} przedstawia klasę planisty włókien.
  Planista zarządza wykonaniem włókien, które otrzymał od swojego właściciela.
  Posiada swój własny kontekst oraz stos wywołań. Jest uprawniony do zmian następujących właściwości włókna:
  \begin{itemize}
    \item może zmienić jego stan na \code{FINISHED}, po zakończeniu pracy włókna;
    \item może zmienić obecnego właściciela włókna.
  \end{itemize}
\par
%
\subsection{Klasa \code{epoller}}
\myownfigure{Epoller}{Epoller.png}{\code{epoller} -- nakładka na mechanizm systemowy \code{epoll}}{.7}
\indent
  Rysunek \arabic{Epoller} przedstawia klasę opakowującą podstawowe operacje mechanizmu \code{epoll}.
  Mechanizm ten umożliwia detekcję:
  \begin{itemize}
    \item zdarzeń dla urządzeń I/O;
    \item nadejścia sygnału lub zdarzenia systemowego;
    \item upłynięcia zadanego czasu (ang. \emph{timer}).
  \end{itemize}
  W~obecnej implementacji biblioteki, obiekt klasy \code{epoller} jest wykorzystywany do wykrywania zdarzeń dla urządzeń wejścia-wyjścia.
  Do tego celu wykorzystywane są wymienione funkcje:
  \begin{itemize}
    \item \code{add(int f)}: dodaje deskryptor urządzenia do obserwowanych;
    \item \code{del(int f)}: usuwa deskryptor urządzenia z obserwowanych;
    \item \function{do\_epolls}: oczekuje przez określony czas na wystąpienie zdarzeń;
    \item \function{get\_last\_epoll\_result}: podaje listę deskryptorów urządzeń, dla których wystąpiło zdarzenie.
  \end{itemize}
\par
%
\subsection{Klasa \code{worker}}
\myownfigure{Worker}{Worker.png}{\code{worker} -- robotnik działający w~obrębie jednego wątku}{.7}
\indent
  Robotnik udostępnia każdemu powierzonemu włóknu:
  \begin{itemize}
    \item możliwość wykonania włókna -- tę funkcję spełnia obiekt klasy \code{scheduler}, będący własnością robotnika;
    \item dostęp do zasobów I/O;
    \item komunikację pomiędzy zarządzanym włóknem, a~dowolnym innym, który działa w~aplikacji.
  \end{itemize}
\par
\indent
Dostęp do I/O (w~obecnej implementacji: zasobów, obsługiwanych przez mechanizm \code{epoll}) jest realizowany w~sposób przezroczysty dla włókna. 
  Funkcje \function{block\_on\_io} oraz \function{do\_connect} blokują wykonanie wywołującego włókna, do momentu, w~którym 
  żądane zasoby systemowe będą dostępne. Włókno jest blokowane, a~jego stan odpowiada wykonywanej operacji:
  \begin{itemize}
    \item \code{BLOCKED\_FOR\_ACCEPT} odpowiada wywołaniu funkcji \function{accept};
    \item \code{BLOCKED\_FOR\_CONNECT} odpowiada wywołaniu funkcji \function{connect};
    \item \code{BLOCKED\_FOR\_READ} odpowiada wywołaniu funkcji \function{read};
    \item \code{BLOCKED\_FOR\_WRITE} odpowiada wywołaniu funkcji \function{write}.
  \end{itemize}
\par
\indent
  Dowolne dwa włókna mogą wymieniać między sobą wiadomości. Ze względu na przynależność włókien do zarządzających nimi robotników, możliwe są dwie możliwości:
  przesyłania wiadomości pomiędzy włóknami:
  \begin{enumerate}
    \item Obydwa włókna są zarządzane przez tego samego robotnika. Robotnik przesyła wiadomość do wewnętrznej kolejki włókna.
    \item Każde włókno jest zarządzane przez innego robotnika. W~tej sytuacji robotnik wysyła wiadomość do nadzorcy (obiekt klasy \code{master}), żądając
      przesłania jej do wszystkich robotników w~systemie, nie oczekując na odpowiedź.
  \end{enumerate}
\par
\indent
  Robotnik, po wstępnej inicjalizacji, jest gotów do wejścia w~pętlę główną, w~której wykonuje następujące czynności:
  \begin{itemize}
    \item przegląda swoją kolejkę wiadomości, a~następnie podejmuje akcje odpowiednie do otrzymanych komunikatów (czynności zlecone przez zarządcę 
      lub przesłanie wiadomości do włókien);
    \item zleca planiście wykonanie wszystkich niezablokowanych włókien;
    \item zleca obiektowi klasy \code{epoller} sprawdzenie stanu (oraz dostępności) zasobów I/O.
  \end{itemize}
\par
%
\subsection{Klasa \code{master}}
    \myownfigure{Master}{Master.png}{Klasa \code{master} -- zarządca robotników}{.7}
%
\indent
  Obiekt klasy \code{master} wytwarza podległych mu \emph{robotników}:  
  \begin{itemize}
    \item funkcja \code{init()} wytwarza dokładnie tylu robotników, ile rdzeni dostępnych dla aplikacji;
    \item funkcja \code{spawn()} służy do zgłoszenia włókna (włókien), które zostanie uruchomione po wykonaniu funkcji \code{run()};
    \item funkcja \code{run()} jest wejściem do pętli głównej zarządcy. Wyjście z~pętli głównej następuje po ustaleniu warunku stopu;
    \item funkcja \code{its\_time\_to\_end()} sprawdza, czy został osiągnięty warunek stopu:
      \begin{itemize}
        \item żaden z~robotników nie obsługuje ani jednego włókna;
        \item \code{master} nie posiada żadnego włókna do uruchomienia.
      \end{itemize}
  \end{itemize}
  Po wytworzeniu robotników, \code{master} pośredniczy w~komunikacji pomiędzy nimi, jak również sprawdza warunek stopu.
  Wytworzenie zarządcy jest realizowane za pomocą funkcji \code{create()}: 
  jest ona odpowiedzialna za inicjalizację zarządców włókien, zwanych \emph{robotnikami}.
  Każdy robotnik odpowiada jednemu z~dostępnych rdzeni, zaś
  \code{master} komunikuje się z~nimi za pomocą kolejek wiadomości.
  Funkcja \code{run\procbr} jest implementacją pętli głównej obiektu \code{master}. Dopóki nie zostanie spełniony warunek stopu,
  wykonywane są dwie czynności: odczyt wiadomości przesłanych przez robotników oraz wykonanie jednej iteracji pętli głównej
  robotnika pracującego w~bieżącym wątku.
\par
\indent
  Obiekt klasy \code{master} posiada trzy pola:
  \begin{itemize}
    \item[\code{own\_slave}:] własny robotnik, który jest wykonywany w~tym samym wątku, co \code{master}, 
      w~każdym kroku wykonywana jest jedna iteracja pętli głównej tego robotnika.
    \item[\code{slaves}:] kolekcja wskaźników do robotników, które są wykonywane w~innych wątkach.
    \item[\code{workload}:] Liczba włókien oczekujących na przekazanie i~uruchomienie w~obiektach klasy \code{worker}.
  \end{itemize}
\par
\newpage
\section{Analiza rozwiązania}
\label{sec:analysis}
\subsection{Kryteria oceny}
\label{sec:criterions}
\indent
	Użyteczność implementacji opisanej w~poprzednim rozdziale można określić na podstawie:
	\begin{enumerate}
		\item Wygody jej używania w~porównaniu z~dostępnymi implementacjami wątków. Ponieważ powszechnie używaną implementacją wątków jest \code{Pthreads},
      porównanie podstawowych scenariuszy użycia tej biblioteki z~analogicznymi scenariuszami użycia biblioteki \code{libmixed} powinno dać jasny pogląd
      na użyteczność \code{libmixed}.
    \item Poprawności działania poszczególnych elementów biblioteki na podstawie testów jednostkowych.
		\item Wydajności biblioteki \code{libmixed}, a~więc porównania czasu działania programów używających \code{libmixed}
      oraz analogicznych programów używających biblioteki \code{Pthreads}.
	\end{enumerate}
\par
%
\subsection{Wygoda użytkowania}
\indent
  Podstawowe scenariusze, na podstawie których można sprawdzić wygodę użytkowania biblioteki \code{libmixed}, to:
  \begin{enumerate}
    \item Uruchomienie środowiska zarządzającego włóknami.
    \item Wytworzenie włókna gotowego do uruchomienia.
    \item Uruchomienie włókna.
    \item Zakończenie działania włókna (po zakończeniu jego działania).
    \item Przesłanie wiadomości do innego włókna.
    \item Użycie I/O: gniazda sieciowe.
    \item Obsługa wyjątków.
  \end{enumerate}
  \newcounter{mixedpthread} \setcounter{mixedpthread}{\value{tabmain}}
\indent
  Tabela \arabic{mixedpthread} zawiera przykłady kodu źródłowego, jaki musi być dodany do programu użytkownika w~celu uzyskania
  wyżej wymienionych celów.
\par
  \begin{center}
  \centering
\footnotesize{
  \begin{tabular}{|c|l|l|} \hline
    Lp & \multicolumn{1}{c|}{\code{libmixed}} & \multicolumn{1}{c|}{\code{Pthreads}} \\ \hline
    1  & \parbox[t]{6cm}{\code{master\dcolon ptr m = master\dcolon create\procbr}}& \parbox[t]{6cm}{\code{--}} \\ \hline
    2  & \parbox[t]{6cm}{\code{class f:public fiber\{ {\ldots} \};\\myfiber f;\\f.init();}} & \parbox[t]{6cm}{\code{void f() \{ {\ldots} \};\\pthread:t t;}} \\ \hline
    3  & \parbox[t]{6cm}{\code{m->spawn( shared\_ptr(f) );}} & \parbox[t]{6cm}{\code{pthread\_create( \&t, 0, f, 0);}} \\ \hline
    4  & \parbox[t]{6cm}{zakończenie działania funkcji \code{f.go()}.} & \parbox[t]{6cm}{zakończenie działania funkcji \code{f()}.} \\ \hline
    5  & \parbox[t]{6cm}{\code{fiber\_message\dcolon ptr fm(new fiber\_message);\\fm->receiver = f';\\f.send\_message(fm);}} & \parbox[t]{6cm}{Brak dedykowanego rozwiązania} \\ \hline
    7  & \parbox[t]{6cm}{\code{f\dcolon start()\{\\try\{ go\procbr; \}\\catch( exception e ) \{ {\ldots}  \}\\\}}} & \parbox[t]{6cm}{\code{void go\procbr \{ {\ldots} \}\\void f\procbr\{\\try\{ go\procbr; \}\\catch( exception e ) \{ {\ldots}  \}\\\}}} \\ \hline
  \end{tabular}
}
  	\mytabcaption{Kod źródłowy potrzebny do realizacji scenariuszy 1\ppauza 5 i~7}
  \end{center}
\par
\indent
  Operacje wejścia--wyjścia można stworzyć na wiele sposobów, ale jeżeli \code{libmixed} udostępnia blokujące (z~punktu widzenia włókna) funkcje obsługujące I/O,
  to w~przypadku wątków rozważane będą także blokujące wywołania funkcji I/O.
  Aby wytworzyć nasłuchujące gniazdo sieciowe, należy wykonać odpowiedni ciąg wywołań systemowych, np. \function{socket}, \function{bind}, \function{listen}
  (dokładniejszy opis można znaleźć na stronie podręcznika dla \code{socket}, rozdział 7). Następnie należy wykonać wywołanie \function{accept} 
  (dla włókna należy użyć funkcji \function{do\_accept}), po którym
  należy uruchomić wątek/włókno obsługujące otwarte połączenie. 
%\par
%\indent
Dla prostoty przyjmijmy, że połączenie musi być obsłużone w~następujący sposób:
  \begin{itemize}
    \item odczyt 10 bajtów z~gniazda o~deskryptorze \code{my\_socket};
    \item zapis 10 bajtów do gniazda;
    \item zamknięcie gniazda.
  \end{itemize}
  Implementacja obsługi połączenia:
  \begin{enumerate}
    \item Przy użyciu \code{Pthreads}:
\begin{verbatim}
  count = ::read( my_socket, rdbuf, 10 );
  count = ::write( my_socket, sndbuf, 10 );
  ::close( my_socket );
\end{verbatim}
    \item Przy użyciu \code{libmixed}:
\begin{verbatim}
  // pobierane/zapisywane dane znajdują się w rw_buffer
  count = do_read( my_socket, 10 ); 
  count = do_write( my_socket, 10 );
  do_close( my_socket );
\end{verbatim}
  \end{enumerate}
\par
\indent
  Jak łatwo zauważyć, zarówno \code{Pthreads}, jak też \code{libmixed} nie wymagają od użytkownika wykonania skomplikowanych
  wywołań w~celu osiągnięcia pożądanych wyników. Tak więc \code{libmixed} jest \emph{równie} wygodna w~użyciu, jak \code{Pthreads}.
\par
\subsection{Testy jednostkowe}
\indent
  Testy jednostkowe zostały zaimplementowane przy użyciu \linebreak środowiska \code{GoogleTest}.
\par
\indent
  Testy jednostkowe należy podzielić na trzy grupy:
  \begin{enumerate}
    \item Testy koprocedur:
      \begin{enumerate}
        \item test operacji \function{yield}: przełączenie pomiędzy bieżącym kontekstem a~kontekstem koprocedury, również wielokrotne.
      \end{enumerate}
    \item Testy modułu \code{message\_queues}:
      \begin{enumerate}
        \item test klasy \code{private\_list}: przesyłanie wiadomości pomiędzy dwoma wątkami, z~których jeden prowadzi aktywny nasłuch (zapętlone wywoływanie
          funkcji \function{top});
        \item test klasy \code{message\_queue}: stabilne przesyłanie wiadomości w~obie strony pomiędzy dwoma wątkami;
      \end{enumerate}
    \item Testy zarządcy włókien wszystkich podległych mu elementów:
      \begin{enumerate}
        \item przesyłanie wiadomości pomiędzy dwoma włóknami -- w~ramach tego samego robotnika;
        \item przesyłanie wiadomości pomiędzy dwoma włóknami -- w~ramach dwóch różnych robotników;
        \item zwrócenie sterowania do zarządcy -- \function{yield};
        \item wytworzenie, inicjalizacja i~uruchomienie (\function{spawn}) nowego włókna przez bieżące.
      \end{enumerate}
  \end{enumerate}
  Wszystkie wymienione testy są spełnione przez bieżącą implementację włókna. Dlatego też można uznać, że jest ona przydatna w~sytuacjach zdefiniowanych
  przez te testy.
\par
\subsection{Testy wydajnościowe}
\indent
	Porównanie wydajności \code{libmixed} z~\code{Pthreads} można sprawdzić za pomocą następujących testów:
	\begin{enumerate}
		\item Czas wykonania \emph{pustych} wątków (ang. \emph{null fork}). Test ten da odpowiedź na pytanie o~wydajność biblioteki w~zakresie
      wytwarzania i~uruchamiania włókien. Liczba \emph{obiektów} (wątków/włókien) jest podstawowym parametrem tego testu: wraz ze wzrostem liczby obiektów do
      uruchomienia, będzie można zmierzyć również wzrost czasu ich obsługi.
    \item Czas wykonania przeplatających się wątków (\emph{yields}). Zarówno włókna, jak i~wątki mogą oddać sterowanie do zarządcy za pomocą wywołania funkcji 
      \function{yield}. Test ten można sparametryzować przez liczbę obiektów do wykonania oraz liczbę operacji \function{yield} wykonywanych
      w~pojedynczym obiekcie.
		\item Czas zapisu danych na standardowe wyjście. Ten test można sparametryzować przez liczbę paczek danych do wysłania (każda w~osobnym obiekcie)
      oraz wielkość każdej pojedynczej paczki.
	\end{enumerate}
\par
\indent
  Konfiguracja maszyny, na której wykonano testy:
  \begin{itemize}
    \item procesor: 
      \begin{itemize}
        \item model: Pentium(R) Dual\dywiz Core  CPU      E5200  @ 2.50GHz;
        \item taktowanie procesora: 1200 MHZ;
        \item cache: 64 KiB pierwszego poziomu, 2 MiB drugiego poziomu;
      \end{itemize}
    \item pamięć RAM: 1 GiB, taktowana zegarem 800 MHz;
    \item system operacyjny Debian GNU/Linux:
      \begin{itemize}
        \item wersja jądra: 3.0.0-2-686-pae;
        \item wersja biblioteki \code{libstdc++}: 6.0.16.
      \end{itemize}
  \end{itemize}
\par
\indent
  Dla każdego parametru (pary parametrów) test został wykonany dziesięciokrotnie, zaś za czas wykonania testu przyjąłem uśredniony 
  czas z~wszystkich 10 prób.
\par
\indent
  Należy wziąć pod uwagę fakt, iż testy były przeprowadzane w~otoczeniu ,,normalnych'' aplikacji, tj. współdzieliło czas wykonania z~charakterystycznymi składnikami
  systemu w~wersji \emph{desktop}, m. in.:
  \begin{itemize}
    \item X Window Environment;
    \item XFCE;
    \item odtwarzacz multimediów  (MPlayer);
    \item przeglądarka internetowa (Iceweasel -- ,,wolna'' (ang. \emph{free}) wersja przeglądarki Firefox).
  \end{itemize}
\par
\newpage
\subsubsection{Wyniki dla testu \code{nullfork}}
\indent
  \code{Nullfork} jest testem, który pokazuje sprawność systemu w~zakresie wytworzenia oraz zakończenia działania wykonywalnego bytu.
  Wykonanie tego testu da odpowiedź na pytania odnośnie systemu operacyjnego, jak też sprawność biblioteki \code{libmixed}:
  \begin{itemize}
    \item Czy ze wzrostem liczby bytów czas ich wykonania rośnie liniowo, czy w~inny sposób?
    \item Czy wytworzenie włókna daje zysk w~porównaniu do do wytworzenia wątku?
  \end{itemize}
\par
\indent
\myownfigure{nullfork}{nullfork.png}{Wykres porównawczy dla testu \code{nullfork} w~zależności od liczby pustych włókien lub wątków}{.65} 
\par
\begin{comment}
\indent
\myownfigure{nullforkLog}{nullforkLog.png}{Wykres porównawczy dla testu \code{nullfork} -- czas wykonania w~skali logarytmicznej}{.65} 
\par
\end{comment}
\indent
  Wynik tego testu jest jednoznaczny: 
  \begin{itemize}
    \item zarówno dla wątków i~włókien, czas ich wytworzenia oraz uruchomienia rośnie liniowo;
    \item czas obsługi wątków jest kilkakrotnie dłuższy od czasu obsługi włókien.
  \end{itemize}
\par
%
\newpage
\subsubsection{Wyniki dla testu \code{yield}}
\indent
  Test \code{yield} posiada dwa parametry: \code{s}~--~liczbę bytów do uruchomienia oraz \code{y}~--~liczbę wykonanych operacji 
  \function{yield}.
  W~celu uzyskania wyników będących podstawą do analizy biblioteki, wybrałem trzy serie testów dla następujących wartości
  \code{s}~i~\code{y}:
  \begin{itemize}
    \item \code{s}=1, \code{y}~$\in \mathbb{A}$,
    \item \code{s}~$\in \mathbb{A}$, \code{y}=10,
    \item \code{s}~$\in \mathbb{A}$, \code{y}=100,
  \end{itemize}
  gdzie $\mathbb{A}$=\{1, 101, 201, \ldots , 9901\}.
\par
\indent
\myownfigure{yield}{yield1n.png}{Wykres porównawczy testu \code{yield} dla \code{s}=1 i~\code{y}~$\in \mathbb{A}$}{.65} 
  Pierwsza seria testów daje następujące informacje:
  \begin{itemize}
    \item operacja \function{yield} dla wątków jest zaimplementowana kilkakrotnie wydajniej niż funkcja \function{swapcontext}, wywoływana 
      przez implementację \function{yield} dla włókien;
    \item czas wykonania \function{yield} da wątków jest ograniczony od dołu jak i~od góry, w~odróżnieniu od ograniczenia czasu wykonania
      \function{swapcontext}.
  \end{itemize}
\par
\begin{comment}
\indent
\myownfigure{yieldLog}{yield1nLog.png}{Wykres porównawczy testu \code{yield} -- czas wykonania w~skali logarytmicznej}{.65} 
\par
\end{comment}
%
\indent
\myownfigure{yieldn10}{yieldn10.png}{Wykres porównawczy dla testu \code{yield} dla \code{s}~$\in \mathbb{A}$ i~\code{y}=10}{.65} 
  Druga seria testów pokazuje taki scenariusz użycia włókien, który pozwala na wykonanie zadań w~wielu oddzielnych włóknach lub wątkach,
  przy rzadkim wywoływaniu operacji \function{yield}. Okazuje się, że w~takim scenariuszu wydajność biblioteki \code{libmixed}
  jest wyższa od wydajności Pthreads.
\par
\begin{comment}
\indent
\myownfigure{yieldn10Log}{yieldn10Log.png}{Wykres porównawczy testu \code{yield} -- czas wykonania w~skali logarytmicznej}{.65} 
\par
\end{comment}
%
\indent
\myownfigure{yieldn100}{yieldn100.png}{Wykres porównawczy testu \code{yield} dla \code{s}~$\in \mathbb{A}$ i~\code{y}=100}{.65} 
\par
\indent
\myownfigure{yieldn100Log}{yieldn100Log.png}{Wykres porównawczy testu \code{yield} dla \code{s}~$\in \mathbb{A}$ i~\code{y}=100 -- czas wykonania w~skali logarytmicznej}{.65} 
  Ostatnia seria pokazuje, że w~ogólnym przypadku, tj. dla dużej liczby wywołań \function{yield} oraz dużej liczby wątków lub włókien,
  mechanizmy zaimplementowane w~Pthreads pozwalają kilkakrotnie szybciej wykonać zadane obliczenia, niż ma to miejsce w~wypadku \code{libmixed}.
\par
%
\newpage
\subsubsection{Wyniki dla testu zapisu do standardowego wyjścia}
\indent
  Test zapisu posiada dwa parametry: \code{n} -- liczba powtórzonych operacji zapisu oraz
  \code{s} -- długość napisów złożonych ze znaku \code{'.'}.
\par
\indent
  Poniżej przedstawiam wyniki testów dla następujących wartości \code{n} oraz \code{s}:
  \begin{itemize}
    \item \code{n} $\in \mathbb{B}$, \code{s}=1000;
    \item \code{n}=1, \code{s}$\in \mathbb{C}$;
    \item \code{n}=100, \code{s}$\in \mathbb{C}$;
  \end{itemize}
  gdzie $\mathbb{B} = \{1,11,21,\ldots ,991\}$, 
  $\mathbb{C} = \{1,1001,2001,3001,\ldots ,99001\}$.
  Czas wykonania testu na poniższych wykresach jest podany w~mikrosekundach.
\par
\indent
  Pierwsza seria testów dała odpowiedź na pytanie o~wydajność operacji \function{do\_write} w~porównaniu z~blokującą operacją \function{write}.
\myownfigure{writen1000min}{writen1000min.png}{Wykres porównawczy dla \code{n}$\in \mathbb{B}$ i~\code{s}=1000 -- porównanie minimalnych czasów wykonania}{.65} 
\myownfigure{writen1000max}{writen1000max.png}{Wykres porównawczy dla \code{n}$\in \mathbb{B}$ i~\code{s}=1000 -- porównanie maksymalnych czasów wykonania}{.65} 
\myownfigure{writen1000avg}{writen1000avg.png}{Wykres porównawczy dla \code{n}$\in \mathbb{B}$ i~\code{s}=1000 -- porównanie uśrednionych czasów wykonania}{.65} 
  Jak łatwo zauważyć, liczba wywołań \function{yield} nie wpływa na wydajność zapisu. Tak więc, wielokrotny zapis do urządzeń wejścia/wyjścia jest w~przypadku
  \code{libmixed} równie wydajny, co odpowiadający mu ciąg blokujących operacji zapisu przy użyciu Pthreads.
\par
\indent 
  Kolejna seria testów miała na celu sprawdzenie zapisu dla zbiorów danych o~różnej wielkości.
\myownfigure{write1nmin}{write1nmin.png}{Wykres porównawczy dla \code{n}=1 i~\code{s}$ \in \mathbb{C}$ -- porównanie minimalnych czasów wykonania}{.65} 
\myownfigure{write1nmax}{write1nmax.png}{Wykres porównawczy dla \code{n}=1 i~\code{s}$ \in \mathbb{C}$ -- porównanie maksymalnych czasów wykonania}{.65} 
\myownfigure{write1navg}{write1navg.png}{Wykres porównawczy dla \code{n}=1 i~\code{s}$ \in \mathbb{C}$ -- porównanie uśrednionych czasów wykonania}{.65} 
  Okazuje się, że implementacja zapisu do I/O w~\code{libmixed} jest równie efektywna jak blokujący zapis w~Pthreads. Co więcej, następna seria testów pokazuje, że
  w~przypadku większej ilości operacji zapisu potwierdza to spostrzeżenie.
\par
\indent
\myownfigure{write100nmin}{write100nmin.png}{Wykres porównawczy dla \code{n}=100 i~\code{s}$ \in \mathbb{C}$ -- porównanie minimalnych czasów wykonania}{.65} 
\myownfigure{write100nmax}{write100nmax.png}{Wykres porównawczy dla \code{n}=100 i~\code{s}$ \in \mathbb{C}$ -- porównanie maksymalnych czasów wykonania}{.65} 
\myownfigure{write100navg}{write100navg.png}{Wykres porównawczy dla \code{n}=100 i~\code{s}$ \in \mathbb{C}$ -- porównanie uśrednionych czasów wykonania}{.65} 
\par
\subsection{Podsumowanie}
\indent
  Na podstawie wyników opisanych wyżej testów, można wysunąć następujące wnioski:
  \begin{enumerate}
    \item Wygoda użycia \code{libmixed} jest porównywalna z~użyciem \code{Pthreads}.
    \item Działanie \code{libmixed} jest poprawne w~przestrzeni ograniczonej przez testy jednostkowe.
    \item Dzięki przeprowadzeniu testów wydajnościowych oraz porównaniu ich z~analogicznymi testami \code{Pthreads}, można stwierdzić
      następujące fakty:
      \begin{itemize}
        \item Wytworzenie włókna, a~więc wykonanie operacji \function{getcontext}, jest operacją szybszą niż wytworzenie wątku za pomocą \function{pthread\_create}.
          Dla jądra Linux, utworzenie nowego wątku oznacza wytworzenie nowego bloku kontrolnego procesu (ang. \emph{Process Control Block}, PCB), zaś
          wytworzenie włókna to wytworzenie niewielkiej (w~testowanym systemie jest to dokładnie 348 bajtów) struktury, zawierającej niezbędne minimum danych
          do prawidłowego wykonywania operacji \function{swapcontext}.
        \item Przełączanie kontekstu pomiędzy wątkami zaimplementowane \linebreak w~jądrze systemu Linux jest kilkakrotnie szybsze od przełączania pomiędzy kontekstami użytkownika,
          zaimplementowanymi w~operacjach \function{swapcontext}.
        \item Operacja \function{pthread\_yield} działa w~czasie kilkakrotnie krótszym niż \linebreak peracja \function{swapcontext}.
        \item Zaimplementowana w~\code{libmixed} obsługa I/O nie ustępuje efektywnością blokującemu dostępowi do tych urządzeń z~poziomu wątków.
      \end{itemize}
  \end{enumerate}
\par
\section{Podsumowanie}
\label{sec:summary}
\indent
  Biblioteka \code{libmixed} może być używana 
\par
%\subsection{Możliwe kierunki rozwoju}
%
\newpage
\rhead{\empty}
%\pagestyle{plain}
\bibliography{bibliography}
\end{document}
