\documentclass{mwart}
\usepackage{polski}
\usepackage{antpolt}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[table]{xcolor}
\usepackage[bookmarks, pdfhighlight=/P, linkbordercolor={1 1 1}, unicode=true]{hyperref}
\usepackage{verbatim}
%\usepackage{qswiss,qcourier}
%\usepackage{sfheaders}

%\usepackage[layout]{tools}

%\setlength{\voffset}{1cm}
%\setlength{\voffset}{1cm}
\author{Mariusz Barycz}
\title{Analiza metod zarządzania wątkami mieszanymi}
\date{\today}
\begin{document} 

\maketitle
\thispagestyle{empty}

\newpage
\tableofcontents
\thispagestyle{empty}

\newpage
% Akapity: bez wcięcia, za to z odstępem pionowym.
% małe hackowanie latex-a: właściwości akapitu po spisie treści:)
\setlength{\parindent}{0pt}
\setlength{\parskip}{1ex plus 0.7ex minus 0.1ex}

\begin{abstract}
	\emph{Tutaj znajdzie się streszczenie pracy.}
\end{abstract}

\newpage
%
\section{Wstęp}
%
\subsection{Architektura systemów komputerowych}
%
\indent 
	W~systemie komputerowym (lub w~skrócie: komputerze) można wyróżnić trzy podstawowe składowe:
	\begin{itemize}
		\item procesor (jednostka centralna, CPU): kontroluje działanie komputera, wykonuje operacje na danych;
		\item pamięć głowna: przechowuje dane oraz programy. Pamięć w~tym kontekście jest z~natury ulotna (po wyłączeniu komputera,
			jej zawartości nie można odzyskać); jeśli w~treści dokumentu pojawi się słowo \emph{pamięć}, odwoływać się będzie ono do
			pamięci głównej;
		\item urządzenia zewnętrzne (peryferia, I/O): służą do wymiany danych pomiędzy komputerem i~światem zewnętrznym.
	\end{itemize}
	Komunikacja pomiędzy nimi odbywa się za pośrednictwem szyny systemowej (ang. \emph{system bus}).
\par
%
\subsubsection{Procesor}
%
\indent
	Procesor jest urządzeniem, które posiada:
	\begin{itemize}
		\item własny zestaw instrukcji (zwanych również rozkazami): ich liczba może wynosić od kilkunastu (architektura RISC, 
			ang. \emph{Reduced Set Instruction Computers}) do kilkset (architektura CISC, ang.
			\emph{Complex Instruction Set Computers}). Często pojedynczy rozkaz posiada wiele trybów adresowania: jako argument
			może użyć własnego rejestru (tryb implikowany), komórki pamięci (tryb bezpośredni), komórki pamięci, której adres został wyliczony
			(tryby: pośredni, pośredni preindeksowany, pośredni postindeksowany). Połączenie instrukcji wraz z~ich trybami adresowania daje 
			stosunkową liczbę rozkazów.
		\item wewnętrzne komórki pamięci, zwane \emph{rejestrami}.
		\item Licznik rozkazów (ang. \emph{prgoram counter}): wyróżniony rejestr, który wskazuje adres następnej instrukcji. 
			Jeśli w~wyniku ostatniej instrukcji następuje skok (warunkowy lub bezwarunkowy), zmieniana jest wartość tego rejestru.
		\item mechanizm \emph{przerwań}: szyna systemowa może w~pewnych sytuacjach poinformować o~wystąpieniu określonego zdarzenia.
			Przerwania można podzielić na maskowalne (procesor zignoruje informację o~wystapienu danego zdarzenia) oraz niemaskowalne.
			Przerwania mogą posiadać priorytety (przerwanie o~niższym priorytecie zostanie zignorowane podczas obsługiwania przerwania
			o~wyższym priorytecie lub jego obsługa rozpocznie się po zakończeniu obecnie obsługiwanego przerwania).
	\end{itemize}
\par
%
\indent
	Procesor przetwarza rozkazy. Można podzielić je na pięć grup:
	\begin{itemize}
		\item odczyt / zapis: wczytanie zawartosci komórki pamięci do rejestru, zapis zawartości rejestru do komórki;
		\item skoki: bezwarunkowe, warunkowe, pośrednie;
		\item operacje logiczne: NOT, AND, OR, XOR;
		\item arytmetyka: suma, różnica, iloczyn, iloraz;
		\item zmiana stanu procesora: maskowanie przerwań, ustawienie / wyczyszczenie flagi przeniesienia.
	\end{itemize}
	Każdy rozkaz jest wykonywany w~określonym czasie, w~zależności od rozkazu wykorzystywane są specyficzne dla danej instrukcji
	jednostki funkcjonale CPU (np. jednostka arytmetyczno\dywiz logiczna dla rozkazów arytmetycznych, lub licznik rozkazów
	dla skoków warunkowych). Czas wykonania jest mierzony w~\emph{cyklach maszynowych}. Należy mieć na uwadze, 
	iż na jeden cykl maszynowy może składać się więcej niż jeden cykl zegarowy, zaś
	producent, informując o~taktowaniu procesora zegarem o~częstotliwości 1 MHz, ma na myśli, że
	w~ciągu sekundy zostanie wykonanych milion cykli zegarowych.
\par
%
\indent
	Wynik wykonania konkretnego rozkazu może powodować zmiany w~rejestrze jednostki centralnej, w~pamięci lub
	też w~urządzeniu zewnętrznym. Co więcej, każdy procesor wykonuje rozkazy w~pewien określony sposób, w~specyficznej dla siebie liczbie kroków.
	Jednakże, dla wszystkich procesorów, możemy wyróżnić podstawowe kroki wykonania rozkazu:
	\begin{enumerate}
	\item Pobranie (ang. \emph{Instruction Fetch, IF}): wymaga komunikacji z~pamięcią.
		pobrany rozkaz po pobraniu jest gotowy do dalszego przetwarzania.
	\item Dekodowanie (ang. \emph{Instruction Decode, ID}):  liczba bajtów, które należy pobrać, może być zmienna:
		nawet gdy długość rozkazu jest niezmienna (np. 2 bajty), jego argumenty (opkodów, ang. \emph{opcode}) mogą być zmiennej długości.
	\item Wykonanie (ang. \emph{Execute, EX}): poszczególne części procesora wykonują działanie w~kolejności określonej przez aktualnie
		wykonywany rozkaz.
	\item Dostęp do pamięci (ang. \emph{Memory Access, MEM}): rozkazy mogą korzystać z~danych zawartych w~komórkach pamięci. Jeśli bieżący rozkaz
		zapisuje do lub odczytuje zawartość pamięci, w~tym kroku jest dokonywana ta operacja.
	\item Zapis (ang. \emph{Write Back, WB}): stan procesora jest aktualizowany o~wynik działania rozkazu.
	\end{enumerate}
\par
%
\indent
	Klasyczne procesory wykonują rozkazy sekwencyjnie. Kolejny rozkaz zostanie wczytany do pamięci dopiero, gdy
	CPU zapisze wynik bieżącego. Do sekwencyjnego wykonywania rozkazów nie potrzeba żadnych dodatkowych mechanizmów,
	jednak w~trakcie wykonania aktywna jest dokładnie jedna składowa procesora, podczas gdy pozostałe są ,,uśpione''
	w~oczekiwaniu na uruchomienie.
	\begin{center}
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|} \hline
	& \multicolumn{5}{c|}{Rozkaz 1} & \multicolumn{5}{c|}{Rozkaz 2}  \\ \cline{2-11}
	& IF & ID & \cellcolor{yellow} EX & MEM & WB & IF & ID & EX & MEM & WB\\ \cline{2-11} \cline{2-11}
	Cykl zegara & 1 & 2 & \cellcolor{yellow} 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
	\end{tabular}\par
	\begin{small} Tabela 1. Sekwencyjne wykonanie dwóch rozkazów \end{small} \par
	\end{center}\par
\par
%
\indent
{\bf Zrównoleglenie wykonania programu na poziomie instrukcji}
\par
%
\indent 
	Pomysł na bardziej efektywne wykorzystanie zasobów jednostki centralnej, to użycie \emph{potokowości} (ang. \emph{pipelining}):
	Jeśli wykonanie bieżącego rozkazu zakończyło się dla komponentu, może on wykonać następny rozkaz.
	\begin{center}
	\begin{tabular}{|c|c|c|c|c|c|c|c|} \hline
	Numer 		 & \multicolumn{7}{c|}{Stan potoku} \\
	rozkazu & \multicolumn{7}{c|}{} \\ \hline
	1 & IF & ID & EX & \cellcolor{yellow} MEM & WB & & \\ \hline
	2 & & IF & ID & \cellcolor{yellow} EX & MEM & WB & \\ \hline
	3 & & & IF & \cellcolor{yellow} ID & EX & MEM & WB \\ \hline
	4 & & & & \cellcolor{yellow} IF & ID & EX & MEM \\ \hline
	5 & & & & \cellcolor{yellow} & IF & ID & EX \\ \hline \hline
	Cykl zegara & 1 & 2 & 3 & \cellcolor{yellow} 4 & 5 & 6 & 7 \\ \hline
	\end{tabular}\par
	\begin{small} Tabela 2. Potokowe wykonanie rozkazów \end{small}
	\end{center}
	Metoda ta pozwala na ,,równoległe'' wykonanie kilku rozkazów na jednym procesorze, w~przykładzie opisanym w~tabeli 2, po upływie 7 cykli
	zostaną wykonane trzy rozkazy. Gdyby rozkazy te były wykonane na jednostce sekwencyjnej, czas ich wykonania byłby ponad dwa razy dłuższy.
\par
%
\indent
	Architektura procesora, która jest uogólnieniem potokowości to \emph{Superskalarność} (ang. \emph{Superscalar}): 
	każdemu krokowi odpowiada co najmniej jeden potok, jednakże występuje redundancja części funkcjonalnych procesora.
	\begin{center}
	\begin{tabular}{|c|c|c|c|c|c|c|c|} \hline
	Numer 		 & \multicolumn{7}{c|}{Stan potoku} \\
	rozkazu & \multicolumn{7}{c|}{} \\ \hline
	1 & IF & ID & EX & \cellcolor{yellow} MEM & WB & & \\ \hline
	2 & IF & ID & EX & \cellcolor{yellow} MEM & WB & & \\ \hline
	3 & & IF & ID & \cellcolor{yellow} EX & MEM & WB & \\ \hline
	4 & & IF & ID & \cellcolor{yellow} EX & MEM & WB & \\ \hline
	5 & & & IF & \cellcolor{yellow} ID & EX & MEM & WB \\ \hline
	6 & & & IF & \cellcolor{yellow} ID & EX & MEM & WB \\ \hline
	7 & & & & \cellcolor{yellow} IF & ID & EX & MEM \\ \hline
	8 & & & & \cellcolor{yellow} IF & ID & EX & MEM \\ \hline
	9 & & & & \cellcolor{yellow} & IF & ID & EX \\ \hline \hline
	10 & & & & \cellcolor{yellow} & IF & ID & EX \\ \hline \hline
	Cykl zegara & 1 & 2 & 3 & \cellcolor{yellow} 4 & 5 & 6 & 7 \\ \hline
	\end{tabular}\par
	\begin{small} Tabela 3. Potokowe wykonanie 10 rozkazów na jednostce superskalarnej\end{small}
	\end{center}
	Jak łatwo zauważyć, superskalarny CPU jest w~stanie przetworzyć nawet wektor instrukcji. Warunkiem koniecznym do osiągnięcia takiego
	wyniku jest brak zależności pomiędzy wynikiem wcześniejszej a~następnej instrukcji.
\par
%
\indent
	Opisane wyżej techniki napotykają jednak na podstawowy problem: w~momencie, gdy bieżącym rozkazem jest skok warunkowy, kolejna wczytana 
	instrukcja nie musi być koniecznie kolejną instrukcją programu. Tak więc, częściowo wykonana instrukcja (lub, w~przypadku jednostek
	superskalarnych, nawet w~pełni wykonane rozkazy) nie powinna wywrzeć wpływu na żaden z~zasobów komputera, 
	a~dodatkowo jest ona niepotrzebnie przetwarzana.
\par
%
\indent
	W~celu zniwelowania niedogodności związanych z~,,nietrafionymi'' skokami warunkowymi, zaczęto stosować technikę 
	\emph{przewidywania skoku} (ang. \emph{branch prediction}): stosowane są heurystyki, które określają najbardziej prawdopodobny
	wynik instrukcji skoku. Dzięki stosowaniu tych heurystyk, udaje się w~dużej liczbie przypadków uniknąć niepotrzebnych obliczeń,
	a~wykonywane są te rozkazy, które rezczywiście są potrzebne do wykonania programu.
	Przewidywanie skoku jest jedną z~technik stosowanych w~mechaniźmie zwaym \emph{Wykonaniem spekulatywnym} (ang. \emph{Speculative execution}):
	wykonanie spekulatywne dopuszcza również wykonanie (przy spełnieniu określonych założeń) części programu znajdującego się za skokiem warunkowym,
	ale jeszcze \emph{przed} wykonaniem tego skoku.
\par
%
\indent
	Technika wykonania określonego fragmentu kodu źródłowego jest stosowana również w~mechaniźmie \emph{Wykonania poza kolejnością}
	(ang. \emph{Out of Order execution, OoO}): jeśli pewien rozkaz używa wartości rejestru, która została już obliczona, to można go wykonać
	poza kolejnością podaną przez autora programu. Dla sekwencji rozkazów:
	\begin{flushleft}
	\begin{tabular}{l}\\
		(1) {\tt add A1,A2,A3 /* dodaj A1 do A2, wynik zapisz do A3 */ } \\
		(2) {\tt add A1,A4,A5 } \\
		(3) {\tt add A2,A3,A7 } \\
		\\
	\end{tabular}
	\end{flushleft}
	można zauważyć , że rozkaz (3) korzysta z~wartości rejestru A3, który jest wyliczony w~(1), jego wykonanie nie ma wpływu na rejestry, z~których 
	korzysta (2), a~więc sekwencja $\langle 1, 3, 2 \rangle $ da po wykonaniu wynik taki sam, jak sekwencja $\langle 1, 2, 3 \rangle $.
\par
%
\indent
	Podczas wykonania programu pewne rejestry procesora są wykorzystywane częściej, zaś inne rzadziej. Aby zwiększyć użycie rzadziej
	używanych rejestrów i~wykonać kolejne rozkazy poza kolejnością, można tymczasowo potraktować nieużywany rejestr jak ten, który miał
	być pierwotnie użyty do wykonania rozkazu (zapisać jego dotychczasową wartość, skopiować wartość z~odpowiedniego rejestru, wykonać instrukcję,
	przywrócić poprzednią wartość tak wykorzystanego rejestru). Taka technika jest zwana 
	\emph{Przemianowaniem rejestrów} (ang. \emph{Register Renaming}).
\par
%
\indent
	Dzięki opisanym wyżej technikom możliwe jest zrównoleglenie wykonania programu (w~stosunku do procesora wykonującego rozkazy sekwencyjnie)
	już na poziomie pojedynczych instrukcji procesora. Stąd też techniki te są określane mianem \emph{instruction level parallelism} (ILP).
	Podstawową zaletą tych technik jest znaczące przyspieszenie działania procesora, jednakże implementacja tych technik w~procesorze pociąga za
	sobą zwiększenie liczby tranzystorów, a~co za tym idzie, zwiększenie temperatury wydzielanej przez CPU.
\par
%
\indent
	Problemem, który jest naturalnie związany z~ILP to zależność od danych (ang. \emph{data dependency}).
	Dotyczy on zachowania oryginalnej chronologii wykonywania rozkazów (zapisu wyników
	ich działania w~procesorze, pamięci i~urządzeniach zewnętrznych). w sekwencji
	\begin{flushleft}
	\begin{tabular}{l l}\\
		(1) & {\tt add Y,Z,X} \\
		(2) & {\tt add U,V,T} \\
		(3) & {\tt mult X,T,L /* zapisz iloczyn X}$\times${\tt T do L */} \\
		(4) & {\tt add L,T,L} \\
	\end{tabular}\\
	\end{flushleft}
	instrukcje (1) i~(2) mogą wyć wykonane w~kolejności $\langle 1,2 \rangle$ jak i~$\langle 2,1 \rangle$, zaś wynik działania instrukcji
	(3) zależy bezpośrednio od wyników działania (1) i~(2). Co więcej, instrukcja (4) nie może być wykonana wcześniej 
	niż po zakończeniu wykonania instrukcji (1), (2) i~(3). Tak więc chronologia wykonania instrukcji (3) i~(4) nie może być zmieniona.
\par
%
\indent
	W~celu rzeczywistego zrównoleglenia działania programu, w~komputerach pojawiło się więcej procesorów,
	które działały niezależnie od siebie. Procesory były pojedynczymi układami, bądź kilka procesorów umieszczano w~jednym układzie. 
	Pojedynczy procesor w~kości zawierającej kilka jednostek centralnych zwany jest \emph{rdzeniem} (ang. \emph{core}).
	Odpowiednio zaprojektowany program,	który korzysta z~kilku procesorów może przyspieszyć swoje działanie nawet proporcjonalnie do ich liczby,
	na których jest wykonywany.	Takie przyspieszenie dzialania programu, choć możliwe, jest rzadko spotykane.
	Dobrą ilustracją problemu przyspieszania działania procesora jest prawo Amdahla, opisane w~dalszej części tego dokumentu.
\par
%
\indent
	Michael J.~Flynn stworzył klasyfikację systemów komputerowych oraz programów (\emph{taksonomia Flynna}), w~której ze względu na liczbę
	strumieni rozkazów oraz danych, wyróżniamy cztery klasy:
	\begin{center}
	\begin{tabular}{|c|c|c|} \hline
													 & Jeden strumień instrukcji	 & Wiele strumieni instukcji \\
													 & (\emph{Single Instruction}) & (\emph{Multiple Instruction}) \\\hline
			Jeden                &     												 &      \\
			strumień danych      &  SISD										   & MISD 			\\
			(\emph{Single Data}) &                             & \\\hline
			Wiele                &     												 &      \\
			strumieni danych     & SIMD                        & MIMD \\
			(\emph{Multiple Data}) & 										 & 			\\\hline
	\end{tabular}
	\begin{small} Tabela 4. Taksonomia Flynna \end{small}
	\end{center}
	Klasy te możemy scharakteryzowac w~następujący sposób:
	\begin{itemize}
		\item SISD jest klasą programów wykonywanych sekwencyjnie na maszynie sekwencyjnej;
		\item SIMD odpowiada programom wykonywanym na maszynie superskalarnej lub na procesorach przetwarzających sygnały (DSP);
		\item MISD jest klasą maszyn i~programów, która ma zastosowanie tam, gdzie liczy się minimalizacja błędów;
		\item MIMD odpowiada programom wykonywanym na wielu procesorach.
	\end{itemize}
\par
\indent
	Komputery sklasyfikowane jako MIMD, ze względu na rodzaj komunikacji pomiędzy procesorami, można podzielić na dwie podklasy:
	\begin{itemize}
		\item o~rozproszonej pamięci: każdy procesor posiada przyporządkowaną
			dla niego pamięć. W~takim układzie procesory wraz z~pamięcią im dedykowaną mogą być traktowane jako oddzielne komputery, 
			zaś komunikacja między nimi przebiega po pewnej ustalonej ścieżce (np. za pomocą połączenia sieciowego).
			Taka architektura systemu komputerowego nazywana jest \emph{wieloprocesorowością asymetryczną} (ang. \emph{asymmetric multiprocessing, AMP}),
			zaś najczęściej jest spotykana w~systemach rozproszonych czy klastrach.
		\item o~dzielonej pamięci: wszystkie procesory korzystają z~tej samej pamięci.
	\end{itemize}
	W~systemach, w~których wszystkie procesory korzystają z~jednej, dzielonej pamięci, komunikacja pomiędzy procesorami odbywa się za jej pomocą.
	Można wyróżnić dwie najczęściej stosowane architektury:
	\begin{itemize}
		\item nadrzędna jednostka/jednostka podrzędna (ang. \emph{master/slave}): jeden z~procesorów posiada uprzywilejowany dostęp do pamięci (master).
			Na tym procesorze są wykonywane najważniejsze dla programu zadania (np. \emph{jądro systemu operacyjnego}, ang. \emph{kernel}),
			zaś pozostałe jednostki centralne posiadają ograniczony dostęp do pamięci (slave), jak również do innych zasobów komputera 
			(np. aplikacje użytkownika systemu operacyjnego).
			Jeśli jednostka podrzędna potrzebuje wykonania pewnego działania, które może być wykonane jedynie przez jednostkę nadrzędną, musi w~tym celu
			przesłać żądanie do jednostki typu master. Taka architektura posiada dwie zasadnicze wady:
			\begin{itemize}
				\item błąd (usterka) jednostki uprzywilejowanej powoduje zerwanie działania programu (systemu operacyjnego);
				\item jednostka typu master może stać się \emph{wąskim gardłem} (ang. \emph{bottleneck}) programu (systemu operacyjnego),
					gdy ilość żądań wykonania specyficznych dla niej operacji przekroczy pewien zależny od niej samej próg, lub też gdy pewne
					operacje będą wykonywane w~sposób nieefektywny.
			\end{itemize}
		\item \emph{SMP} (ang. \emph{symmetric multiprocessing}): wszystkie procesory w~systemie komputerowym posiadają identyczne przywileje
			dostępu do pamięci oraz innych jego zasobów. Dzięki temu, możliwe jest wykonywanie jednej aplikacji na wielu procesorach jednocześnie,
			możliwa jest również ,,wędrówka'' wydzielonych części aplikacji po wszystkich dostępnych w~komputerze procesorach.
	\end{itemize}
\par
%
\indent
	Opisane powyżej techniki stosowane w~architekturach procesorów, jak również same architektury systemów operacyjnych, kładą nacisk na
	zrównoleglenie wykonywania programów. Głównym wyzwaniem, jakie stoi przed programistą, jest takie zaprojektowanie aplikacji,
	aby można było ją wykonać równolegle na jak największej liczbie procesorów, co przełoży się na krótszy czas wykonania.
	Aplikacja będzie komunikować się ze światem zewnętrznym, a~w~szczególności z~użytkownikiem o~wiele sprawniej, niż ta sama aplikacja,
	ale zaprojektowana w~sposób sekwencyjny.
\par
%
\indent
	Można zauważyć, że wzrost mocy obliczeniowej maszyn wieloprocesorowych (wielordzeniowych) w~stosunku do maszyn klasy SISD (SIMD) jest
	analogiczny do wzrostu mocy obliczeniowej procesora posiadającego architekturę ILP do procesora posiadającego architekturę sekwencyjną.
	Jednakże, aby wykorzystać potencjał architektur równoległych,
	zarówno ILP jak i~MIMD wymagają odpowiednio zaprojektowanych i~zaprogramowanych programów.
\par
%
\subsubsection{Pamięć}
\indent
	Innym poważnym problemem, z~jakim można się obecnie spotkać, jest dostęp do pamięci RAM: od początku lat 90. XX~wieku różnica
	pomiędzy częstotliwością taktowania procesora, a~pamięci RAM zwiększyła się drastycznie. Już wtedy zaczęto zauważać
	ten problem, przyrównując go, z~punktu widzenia procesora, do uderzenia w~mur (ang. \emph{Memory Wall}). Aby ominąć ten problem,
	w~procesorach umieszczano pamięć podręczną (ang. \emph{cache}), która była taktowana tak jak sam procesor (cache pierwszego poziomu, L1 cache),
	lub częstotliwością niewiele odbiegającą od częstotliwości taktowania procesora (L2 cache). Oczywiście ilość pamięci podręcznej
	była nieporównywalnie mniejsza od ilości pamięci RAM, tak więc pojawienie się pamięci cache wymusiło stosowanie technik, które nie
	były potrzebne dotychczas.
\par
%
\indent
	Okazuje się więc, że zwiększanie częstotliwości taktowania procesora nie wpływa na wzrost jego wydajności w~takim stopniu, jak ILP.
	Należy również pamiętać o~zależności temperatury wydzielanej przez jednostkę centralną w~stosunku do wzrostu częstotliwości taktowania,
	która rośnie wykładniczo.
	%Co więcej, sugerowany przez producentów wzrost wydajności procesora jest traktowany jako mit (ang. \emph{megahertz myth}).
\par
%
\indent
	Stosowanie coraz bardziej zaawansowanych technik (jak również uniknięcie przegrzania jednostki centralnej)
	wymusiło miniaturyzację samego procesora. Następnym krokiem było umieszczenie w~jednostce
	centralnej (CPU) kilku procesorów, zwanych \emph{rdzeniami} (ang. \emph{cores}). Wraz z~pojawieniem się wielordzeniowej jednostki centralnej,
	w~celu efektywnego jej wykorzystania, należy uwzględnić wszystkie problemy związane z~programowaniem równoległym, w~szczególności
	wykonanie aplikacji, w~celu efektywnego wykorzystania zasobów, powinno być zrównoleglone w~jak największym stopniu.
\par

\subsubsection{Urządzenia zewnętrzne}
\indent
	Urządzenia zewnętrzne, znane również jako \emph{peryferia}, \emph{urządzenia wejścia--wyjścia}, \emph{I/O} (\emph{ang. Input/Output}),
	odpowiadają za komunikację komputera ze światem zewnętrznym. Można podzielić je według właściwości odczytu/zapisu na trzy grupy:
	\begin{itemize}
		\item{tylko odczyt danych, np.} klawiatura, mysz, 
		\item{tylko zapis, np.} wyświetlacz,
		\item{odczyt i~zapis, np.} karta sieciowa, graficzna, dźwiękowa, \ldots
	\end{itemize}
\par
\subsection{System operacyjny}
%
\indent
	System operacyjny (ang. \emph{operating system}) jest programem, który kontroluje wykonanie aplikacji (programów),
	może być postrzegany jako pośrednik (interfejs) pomiędzy aplikacją a~sprzętem (systemem komputerowym), na którym jest wykonywany.
	Musi spełniać następujące warunki:
	\begin{itemize}
		\item wygoda: system sprawia, że komputer jest wygodny w~użyciu; %An OS makes a computer more convenient to use.
		\item wydajność: system wydajnie zarządza zasobami komputera; % An OS allows the computer system resources to be used in an efficient manner.
		\item Ability to evolve: An OS should be constructed in such a way as to permit the
      effective development, testing, and introduction of new system functions without interfering with service.
	\end{itemize}
\par
%
\indent
	Systemy operacyjne, ze względu na sposób wykonywania zadań, można podzielić na cztery grupy:
	\begin{center}
	\begin{tabular}{|c|c|c|} \hline
													 & Jeden wątek w~procesie   	 & Wiele wątków w~procesie \\\hline
			Jeden proces               &  SISD										   & MISD 			\\\hline
			Wiele procesów             & SIMD                        & MIMD \\\hline
	\end{tabular}\\
	\begin{small} Tabela 5. Klasyfikacja systemów operacyjnych \end{small}
	\end{center}
\par
%
\indent
	Aplikację można roapztrywać jako zbiór zadań, które wykonywane są w~określonym kontekście. Może zdarzyć się również, że pewne zadania
	mogą być wykonane po zakończeniu działania innych. Może się zdarzyć, że pewne zadania korzystają ze wspólnych zasobów.
	Systemy operacyjne udostępniają podstawową abstrakcję dla zadań: \emph{procesy}. Wykonanie procesu odbywa się w~jednym lub wielu \emph{wątkach}
	Systemy operacyjne można podzielić na analogiczne klasy do tych z~taksonomii Flynna, ale ze względu na sposób zarządzania zadaniami.
\par
%
\subsection{Motywacja} 
%
\indent
	O~ile ILP jest z~reguły przezroczyste dla programisty (optymalizacja jest dokonywana przez kompilator lub jest wykonywana w~trakcie wykonywania programu
	przez jednostkę centralną),	o~tyle programista musi zaprojektować (i~zaimplementować) aplikację tak, aby mogła korzystać z~wielordzeniowej
	architektury jednostki centralnej.
\par
%
\indent
	Współczesne systemy operacyjne udostępniają programiście narzędzia, które mogą być użyte do maksymalnego wykorzystania 
	wielordzeniowej architektury CPU: są to \emph{procesy} oraz \emph{wątki}.
\par
%
\indent
	Aplikacja jest najczęściej zbiorem różnych zadań wykorzystujących wspólne zasoby, tak więc z~punktu widzenia systemu operacyjnego 
	powinna działać w~obrębie procesu, który działa na udostępnianych przez system zasobach (pamięć, deskryptory plików, czas wykonania, itp.).
	Poszczególne zadania realizowane w~ramach aplikacji winny być wątkami korzystającymi ze wspólnych zasobów.
	Ze względu na naturę wątków, niektóre zadania wymagają wątków przestrzeni jądra (zapewniające skalowalność aplikacji), zaś inne wymagają
	wątków przestrzeni użytkownika (wątek jest przyporządkowany do jednego rdzenia) lub \emph{włókien} (ang. \emph{fibers}, autonomiczne fragmenty
	aplikacji, które dobrowolnie przekazują między siebie sterowanie).
\par
%
\indent
	Niektóre systemy operacyjne (NetBSD, OpenSolaris) udostępniają wątki mieszane, gdzie użytkownik decyduje, z~jakim rodzajem wątku 
	chce związać konkretne zadanie.
\par
%
\indent
	W systemie Linux użytkownik ma do dyspozycji wątki przestrzeni jądra \linebreak (\emph{PThreads}), zgodne ze standardem POSIX0.1.
	Dostępne są biblioteki implementujące włókna (\emph{GNU~Pth}, \emph{State~Threads}). Programista decyduje o~rodzaju użytych wątków.
\par
%
\indent
	W systemie Windows zaimplementowane są wątki przestrzeni jądra, dodatkowo można skorzystać z~włókien, które dostarcza producent systemu.
	Niestety, ich implementacja nie jest zgodna ze standardem POSIX. Również tutaj decyzja o~wyborze rodzaju wątku dla zadania należy do użytkownika.
\par
%
\subsection{Cel}
%
\indent
	Cel tej pracy to zbadanie możliwości elastycznego zarządania wątkami mieszanymi w~taki sposób, aby zminimalizować liczbę odwołań systemowych.
	Co więcej, wątki mają być zarządzane w~sposób przezroczysty dla użytkownika (programisty). 
\par
%

\newpage
\section{Podstawy}

\subsection{Koprocedury}
%
\indent
	Procedurę można przedstawić jako ciąg instrukcji $P=\langle c_1,c_2,\ldots ,c_n\rangle$, zaś jej wywołanie jako 
	$C=\langle c_1^P,\ldots,c_m^P\rangle, \mathrm{ } (m \leq n)$~--~jej
	podciąg. Dla dwóch wywołań 
	\begin{displaymath}
	\begin{array}{l}
	C_1= \langle c_1^1,c_2^1,\ldots ,c_k^1 \rangle \\
	\mathrm{oraz}\\
	C_2= \langle c_1^2,c_2^2,\ldots ,c_l^2 \rangle \mathrm{~} (k,l > 0), 
	\end{array}
	\end{displaymath}
	mamy $c_1^1 = c_2^1$, zaś ostatnie elementy tych ciągów wcale nie muszą być równe.
\par
\indent
	Każda procedura posiada specyficzne dla niej obiekty zawarte w~jej \emph{rekordzie aktywacji},
	umieszczonym na stosie tych rekordów. Rekord aktywacji zawiera stan procedury, który znika wraz 
	z~jej zakończeniem. Tak więc, stan procedury jest ulotny.
\par
	Koprocedury są ,,uogólnionymi'' procedurami. O~ile procedury posiadają własne zmienne
	przechowywane na stosie oraz mogą dostarczyć dokładnie jedną wartość po zakończeniu
	działania, o~tyle koprocedury:
	\begin{itemize}
	\item posiadają własny stos wywołań;
	\item mogą przekazać do strony wywołującej co najmniej jedną wartość.
	\end{itemize}
	Powyższe właściwości koprocedur predestynują je jako naturalna podstawę dla wątków:
	nie są one tak ulotne jak procedury, gdyż po zwróceniu wyniku ich stan jest zapamiętywany,
	a~kolejne wywołanie koprocedury jest jej kontynuacją od miejsca poprzedzającego przekazanie
	ostatniego wyniku. Co więcej, koprocedura może wywoływać prcedury (jak również inne koprocedury)
	we własnym kontekście, a~więc, przy minimalnym nakładzie ze strony programisty, możliwe jest
	zaimplementowanie TLS dla bieżącej koprocedury.
\par

\indent
	W wielowątkowym systemie operacyjnym, proces jest jednostką o~chronionym dostępie do 
	procesorów, innych procesów, plików oraz innych zasobów wejścia-wyjścia. Ponadto, system
	traktuje go jako autonomiczny byt, który posiada własną przestrzeń adresową (wirtualna 
	przestrzeń adresowa), oraz czas wykonania.
\par
%
\indent
	W~takim systemie wątek jest przyporządkowany do dokładnie jednego procesu, a~sam proces 
	może zawierać co najmniej jeden wątek. Wątki w~obrębie procesu dzielą tę samą przestrzeń
	adresową, jak i~pozostałe zasoby. Czas wykonania wątków jednego procesu jest równy czasowi
	jego wykonania. Każdemu z~nich są przyporządkowane:
	\begin{itemize}
	\item stan (uruchomiony, gotowy, itp.);
	\item kontekst (gdy nie jest aktualnie wykonywany);
	\item stos wywołań;
	\item prywatna przestrzeń adresowa (ang. \emph{Thread Local Storage, TLS}).
	\end{itemize}
\par
\subsection{Wątki przestrzeni jądra}

%
\indent
	Wątki przestrzeni jądra (ang. \emph{Kernel--Level Threads, KLT}) są zarządzane w~całości przez system operacyjny. 
	Większość obecnych systemów operacyjnych oferuje KLT użytkownikowi. Czasami wątki przestrzeni jądra są nazywane
	\emph{procesami wagi lekkiej} (ang. \emph{Lightweight Proccess}), gdyż przełączanie pomiędzy nimi jest o~wiele
	szybsze niż pomiędzy procesami, zaś każdy wątek otrzymuje od systemu określoną porcję czasu procesora.
	KLT realizują model 1:1. Odzwierciedla on przyporządkowanie \emph{jednego wątku użytkownika dla jednego wątku jądra}.
\par
%
\indent
	Podstawowa korzyść, jaką można uzyskać z~tego powodu, to nieblokujący dostęp do urządzeń wejścia-wyjścia:
	jeśli jeden z~wątków oczekuje na dane z~IO, wykonanie pozostałych wątków nie jest wstrzymywane.
	Z~tego powodu aplikacje, które w~trakcie działania często odwołują się do urządzeń zewnętrznych, korzystają
	z~KLT.
\par
%
\indent
	Inną korzyścią wątków przestrzeni jądra jest rozdystrybuowanie ich na wiele rdzeni. Mechanizm ten jest przezroczysty
	dla użytkownika. Dzięki niemu, niezależne obliczenia mogą wykonywać się równocześnie, co może znacząco wpłynąć na
	wydajność aplikacji.
\par
%
\indent
	Należy pamiętać, że KLT są zarządzane w~całości przez system operacyjny. Wobec tego, zmiana stanu wątku, jego uruchomienie,
	wstrzymanie, jak również sposób zarządzania pulą wątków jest w~pełni zależna od jądra systemu i~użytkownik jest skazany
	na decyzje systemu operacyjnego odnośnie podstawowych operacji na wątkach. Co więcej, taki sposób zarządzania wątkami,
	jest obarczony kosztami związanymi z~komunikacją z~jądrem systemu.
\par
%
\indent
	Użytkownik korzystający z~wątków przestrzeni jądra może spotkać się z~problemem \emph{wyścigów} (ang. \emph{Race Conditions}):
	dwa wątki w~tym samym czasie wykonują operacje na tych samych zasobach. Ponieważ system operacyjny przerywa pracę wątków w~sposób
	niezależny od działania poszczególnych wątków, może zdarzyć się sytuacja, gdy operacje jednego wątku \emph{przeplatają się} z~operacjami
	drugiego wątku (równie dobrze może to być o~wiele większa liczba wątków!) na tym samym zasobie. W~takiej sytuacji, wynik działania wątków
	może prowadzić do nieprzewidywalnych wyników, które mogą wypaczyć wynik działania aplikacji, lub nawet doprowadzić do przerwania jej wykonania.
\par
%
\indent
	Aby zaradzić temu problemowi, stworzony został mechanizm \emph{wzajemnego wykluczania} (ang. \emph{Mutual Exclusion, mutex}):
	jeśli dany zasób jest wolny, wówczas dostęp do niego otrzymuje dokładnie jeden wątek, zaś inne wątki czekają na zwolnienie tego zasobu.
	Wątki mogą być uśpione lub oczekiwać aktywnie na przydzielenie zasobu, jednakże są one w~jakiś sposób zablokowane.  
	Okazuje się, że mechanizm wzajemnego wykluczania wiąże się z~różnego rodzaju zagrożeniami. Najpoważniejsze z~nich to zakleszczenie 
	(ang. \emph{deadlock}) i~zagłodzenie (ang. \emph{starvation}).
\par
%
\indent
	Zakleszczenie występuje w~momencie gdy jeden wątek wykonuje operacje na zasobie A, a~następnie (nie zwalniając A) zgłasza zapotrzebowanie
	na zasób B, który jest zarezerwowany dla drugiego wątku, który oczekuje na zwolnienie zasobu A.
\par
%
\indent
	Zagłodzenie wątku występuje wtedy, gdy pewien wątek oczekuje na dostęp do zasobu, lecz nie jest on do tego zasobu dopuszczony.
\par

\subsection{Wątki przestrzeni użytkownika}
%
\indent
	Wątki przestrzeni użytkownika (ang. \emph{User--Level Threads, ULT}) nie są widoczne dla systemu operacyjnego w~taki sposób,
	jak ma to miejsce w~wypadku KLT. Podstawowa różnica pomiędzy tymi dwoma rodzajami wątków polega na podziale czasu pomiędzy
	poszczególne wątki: uruchomienie (wznawianie) oraz przerywanie działania KLT jest dokonywane przez system operacyjny, zaś 
	zarządzanie działaniem ULT jest zadaniem dla użytkownika. Strategie uruchamiania poszczególnych wątków przestrzeni jądra
	(ang. \emph{scheduling}) jest również odpowiedzialnością systemu operacyjnego, co w~przypadku ULT jest także powinnością 
	użytkownika. Wątki przestrzeni użytkownika są z~tego powodu o~wiele lżejsze: przełączanie pomiędzy nimi nie jest tak czasochłonne
	jak w~wypadku KLT. Co więcej, zarządzanie ULT może być bardziej dopasowane do charakteru aplikacji: niektóre wątki potrzebują
	prostego zarządzania (pierwszy wątek, drugi, \ldots, $n$-ty, pierwszy, \ldots -- algorytm \emph{Round-Robin}),
	inne aplikacje wymagają nadawania poszczególnym wątkom priorytetów, itp. Co więcej, przezroczystość ULT dla systemu nie zakłóca
	jego własnej polityki zarządzania wątkami. Model, który odpowiada wątkom przestrzeni użytkownika, to N:1.
	ULT są nazywane \emph{zielonymi wątkami} (ang. \emph{Green Threads}).
\par
%
\indent
	Zaletą tego rozwiązania jest także łatwość uniknięcia zjawiska wyścigów. Ponieważ wszystkie ULT są wykonywane
	w~ramach jednego procesu, wątek posiada wyłączny dostęp do wszystkich jego zasobów,
	nie modyfikowany przez żaden inny wątek.
\par
%
\indent
	Jeśli jeden z~wątków przestrzeni
	użytkownika zostanie zablokowany (np. podczas wykonywania operacji na IO), wówczas działanie innych wątków będzie również zablokowane.
	Aby uniknąć takich sytuacji, operacje blokujące są często opakowane w~taki sposób, by nie blokować wykonania wątku (\emph{jacketing}).
\par
%
\indent
	Ważną cechą ULT jest ich niezależność od systemu operacyjnego, w~jakim pracują: nie potrzebują one mechanizmu wywłaszczania
	(ang. \emph{preemption}), gdyż kontrola nad wykonaniem wątku jest wykonywana po stronie użytkownika.
\par
%
\subsection{Wątki mieszane}
%
\indent
	Wątki mieszane są implementacją modelu N:M. Wątki w~tym modelu są zarządzane zarówno 
	przez system operacyjny, jak też użytkownika. Ich celem jest połączenie zalet KLT i ULT. Istnieją implementacje, które
	modyfikują system operacyjny, jak również takie, które nie ingerują w~jego strukturę. Opisana w~tej pracy implementacja
	wątków mieszanych stosuje drugą metodę.
\par
\subsection{Wzajemne wykluczanie}
%
\indent
	Jak wspomniano wcześniej, wzajemne wykluczanie jest mechanizmem używanym w~celu uniknięcia zjawiska wyścigów.
	Aby wykluczyć taką sytuację, wątki wykonują działania na współdzielonym zasobie w~ramach tzw. \emph{sekcji krytycznej}
	(ang. \emph{critical section}).
\par
%
\indent
	Sekcję krytyczną można zapisać w~następujący sposób:
	\begin{verbatim}

    Wejście_do_sekcji_krytycznej();

    Sekcja_krytyczna(); // wykonanie operacji
                        // na współdzielonych zasobach

    Wyjście_z_sekcji_krytycznej();
	\end{verbatim}
	
	Operacje wejścia i~wyjścia z~sekcji krytycznej muszą spełniać następujące warunki:
	\begin{itemize}
	\item[{\bf M}] Wzajemne wykluczanie : dokładnie jeden wątek znajduje się w~sekcji krytycznej
	(Jeśli nastąpi przełączenie tego wątku na inny -- jest on nadal w~sekcji krytycznej, a~więc inne wątki
	w~dalszym ciągu muszą czekać na jego wyjście z~sekcji krytycznej).
	\item[{\bf P}] Postęp (ang. \emph{Progress}): jeśli żaden wątek nie znajduje się w~sekcji krytycznej, a~istnieją wątki oczekujące na wejście
	do własnych sekcji krytycznych, to decyzja o~wejściu do sekcji krytycznej zapada pomiędzy wątkami, które oczekują na wejście
	lub wychodzą z~sekcji krytycznej. Co więcej, decyzja ta musi zapaść (nie może być odraczana w~nieskończoność).
	\item[{\bf B}] Ograniczone czekanie (ang. \emph{Bounded waiting}): wątek znajdzie się w~sekcji krytycznej najpóźniej po określonej
	liczbie prób.
	\end{itemize}
\par
\subsubsection{Algorytm Petersona}
%
\indent
	Algorytm jest rozwiązaniem problemu sekcji krytycznej dla dwóch wątków. 
\par


%\end{document}
%
%\newpage
%\input{scheduling_strategies.tex}
%
%\newpage
%\input{mechanisms.tex}
%
%\newpage
%\input{implementation.tex}
%
%\newpage
%\input{testing.tex}
%
%\newpage
%\input{summary.tex}
%
%\newpage
%\input{bibliography.tex}
%
\end{document}
